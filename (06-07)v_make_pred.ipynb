{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e9457-0887-469b-830b-6f7396be6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies import\n",
    "from common_dependencies import *\n",
    "import logging\n",
    "logger = logging.getLogger('main.(02-05)v_make_pred.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34591ee-be65-42f8-8e4b-a8d2f49cee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for files with original data\n",
    "PATH_TO_DATA = {\n",
    "    'run_1': \n",
    "        ('data/original_data/run_1/run1_WM32_data.csv',\n",
    "        'data/original_data/run_1/run1_WM32_defects.csv',\n",
    "        'data/original_data/run_1/run1_WM32_pipe.csv'),\n",
    "    'run_2':\n",
    "        ('data/original_data/run_2/run2_WM32_data.csv',\n",
    "        'data/original_data/run_2/run2_WM32_defects.csv',\n",
    "        'data/original_data/run_2/run2_WM32_pipe.csv')\n",
    "}\n",
    "\n",
    "def get_quadratic_sequence(max_val: int, res_list: list[int] = [4]) -> list[int]:\n",
    "    if max_val % 2 == 1:\n",
    "        raise ValueError('max_val should be integer divisible by 2')\n",
    "        \n",
    "    if max(res_list) == max_val:\n",
    "        return res_list\n",
    "    res_list.append(max(res_list) * 2)\n",
    "    return get_quadratic_sequence(max_val, res_list)\n",
    "\n",
    "\n",
    "PATH_TO_MODEL = 'networks/CNN'\n",
    "RUNS = [1, 2]\n",
    "MODEL_VER = '07'\n",
    "MODEL_NUM = '01'\n",
    "XSHIFT = 200\n",
    "\n",
    "for name in os.listdir(PATH_TO_MODEL):\n",
    "    res = re.match(F'(id=v{MODEL_VER}n{MODEL_NUM}).*', name)\n",
    "    if not res is None:\n",
    "        PATH_TO_MODEL += '/' + res[0]\n",
    "        break\n",
    "\n",
    "# детерминация случайных величин, отвечающих за выбор первоначальных весов и биасов\n",
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3135c-1cb6-4061-b326-664c758c1944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "load_model = keras.models.load_model(PATH_TO_MODEL)\n",
    "CROP_SIZE = load_model.inputs[0].shape[1]\n",
    "CROP_STEPS = get_quadratic_sequence(CROP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194db4d-2777-4eff-80b9-cd61937abe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_fast(model, \n",
    "                   path_to_data_tuple: tuple(),\n",
    "                   x_shift: int,\n",
    "                   crop_size: int, \n",
    "                   crop_step: int):\n",
    "\n",
    "    # read data and roll dfs along x axis\n",
    "    x_df, y_df = dw.get_x_and_y_data(*path_to_data_tuple)\n",
    "    x_df = dw.roll_df(x_df, x_shift, axis=1)\n",
    "    y_df = dw.roll_df(y_df, x_shift, axis=1)\n",
    "\n",
    "    # save the read df shape\n",
    "    or_rows = x_df.shape[0]\n",
    "    or_cols = x_df.shape[1]\n",
    "\n",
    "    # extend x and y dfs for prediction and crops dividing\n",
    "    ex_x_df = dw.extend_df_for_prediction(x_df, crop_size)\n",
    "    ex_x_df = dw.extend_df_for_crops_dividing(ex_x_df, crop_size, crop_step)\n",
    "    ex_y_df = dw.extend_df_for_prediction(y_df, crop_size)\n",
    "    ex_y_df = dw.extend_df_for_crops_dividing(ex_y_df, crop_size, crop_step)\n",
    "\n",
    "    ex_rows = ex_x_df.shape[0]\n",
    "    ex_cols = ex_x_df.shape[1]\n",
    "\n",
    "    # reshape x df to set of crops\n",
    "    (x_data_time,\n",
    "    x_data_amp) = dw.reshape_x_df_to_image_like_numpy(ex_x_df, crop_size, crop_step)\n",
    "\n",
    "    # standardize x data\n",
    "    x_data_time = dw.standardize_data(x_data_time)\n",
    "    x_data_amp = dw.standardize_data(x_data_amp)\n",
    "    \n",
    "    res = np.array(model.predict([x_data_time, x_data_amp]))\n",
    "    res = np.squeeze(res, axis=2)\n",
    "    \n",
    "    bool_res = res[0,:]\n",
    "    depth_res = res[1,:]\n",
    "\n",
    "    extend_size_arr = np.ones((ex_rows, ex_cols))     \n",
    "    \n",
    "    bool_res_it = iter(bool_res) \n",
    "    depth_res_it = iter(depth_res) \n",
    "    \n",
    "    for j in range(0,  ex_cols - crop_size + 1, crop_step):\n",
    "        for i in range(0, ex_rows - crop_size + 1, crop_step):  \n",
    "            bool_temp_add = next(bool_res_it)\n",
    "            depth_temp_add = next(depth_res_it)\n",
    "            extend_size_arr[i:i+crop_size, j:j+crop_size] += bool_temp_add * depth_temp_add\n",
    "    \n",
    "    orig_size_arr = extend_size_arr[crop_size - 1:, crop_size - 1:][:or_rows, :or_cols]\n",
    "\n",
    "    extend_size_result_df = pd.DataFrame(data=extend_size_arr, \n",
    "                             columns=ex_x_df.columns, \n",
    "                             index=ex_x_df.index)\n",
    "\n",
    "    orig_size_result_df = pd.DataFrame(data=orig_size_arr, \n",
    "                       columns=x_df.columns.tolist(), \n",
    "                       index=x_df.index.tolist())\n",
    "    \n",
    "    return orig_size_result_df, extend_size_result_df, y_df, ex_y_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc6ea9-3f1e-44a6-8a24-7d05b95722ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in RUNS:\n",
    "    for crop_step in CROP_STEPS:\n",
    "        logger.debug(f'run: {run}, crop step: {crop_step}')\n",
    "        (orig_size_result_df, \n",
    "        extend_size_result_df,\n",
    "        orig_size_reference_df, \n",
    "        extend_size_reference_df) = make_pred_fast(load_model, PATH_TO_DATA[f'run_{run}'], XSHIFT, CROP_SIZE, crop_step)\n",
    "\n",
    "        path_to_run = f'data/drawing_data/model_id=v{MODEL_VER}n{MODEL_NUM}/run_{run}/' \n",
    "        res_file_name = f'model_id=v{MODEL_VER}n{MODEL_NUM}_crop(size={CROP_SIZE},step={crop_step})_shift(x={XSHIFT},y=0).xlsx'\n",
    "        \n",
    "        if not os.path.exists(path_to_run):\n",
    "            os.makedirs(path_to_run)\n",
    "        \n",
    "        with pd.ExcelWriter(os.path.join(path_to_run, res_file_name)) as writer:  \n",
    "            orig_size_result_df.to_excel(writer, sheet_name='orig_size_result')\n",
    "            extend_size_result_df.to_excel(writer, sheet_name='extend_size_result')\n",
    "            \n",
    "            orig_size_reference_df.to_excel(writer, sheet_name='orig_size_reference')\n",
    "            extend_size_reference_df.to_excel(writer, sheet_name='extend_size_reference')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
