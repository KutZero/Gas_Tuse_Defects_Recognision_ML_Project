{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde58157-7750-45b9-a343-b46e3c74b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies import\n",
    "from common_dependencies import *\n",
    "from typing import NamedTuple\n",
    "import model_versions as mv\n",
    "import logging\n",
    "logger = logging.getLogger(f'main.model_train')\n",
    "# детерминация случайных величин, отвечающих за выбор первоначальных весов и биасов\n",
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)\n",
    "np.random.seed(290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf461c0-86ef-4815-a965-1e766c1f33b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paths for files with original data\n",
    "PATH_TO_DATA = {\n",
    "    'run_1': \n",
    "        ('data/original_data/run_1/run1_WM32_data.csv',\n",
    "        'data/original_data/run_1/run1_WM32_defects.csv',\n",
    "        'data/original_data/run_1/run1_WM32_pipe.csv'),\n",
    "    'run_2':\n",
    "        ('data/original_data/run_2/run2_WM32_data.csv',\n",
    "        'data/original_data/run_2/run2_WM32_defects.csv',\n",
    "        'data/original_data/run_2/run2_WM32_pipe.csv')\n",
    "}\n",
    "\n",
    "CROP_SIZE = 20\n",
    "#CROP_STEP = 4\n",
    "\n",
    "DataCrop = NamedTuple(\"DataCrop\", [('top', int), ('bottom', int),('left', int), ('right', int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247b716-cc7d-4c7f-ae8f-7e7b09df0cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_gen(path_to_data_tuple: tuple(),\n",
    "                x_shift: int,\n",
    "                data_part: DataCrop,\n",
    "                crop_size: int, \n",
    "                crop_step: int):\n",
    "    logger.debug(\"start\")\n",
    "    x_df, y_df = dw.get_x_and_y_data(*path_to_data_tuple)\n",
    "    #dw.draw_defects_map(y_df, title=f'Read defects map')\n",
    "\n",
    "    x_df = dw.roll_df(x_df, x_shift, 1)\n",
    "    y_df = dw.roll_df(y_df, x_shift, 1)\n",
    "    dw.draw_defects_map(y_df, title=f'The shifted by {x_shift} on x axis read defects map')\n",
    "    \n",
    "    x_df = x_df.iloc[data_part.top:data_part.bottom, data_part.left:data_part.right]\n",
    "    y_df = y_df.iloc[data_part.top:data_part.bottom, data_part.left:data_part.right]\n",
    "    dw.draw_defects_map(y_df, title=f'The part took for learning')\n",
    "    \n",
    "    x_df = dw.extend_df_for_crops_dividing(x_df, crop_size, crop_step)\n",
    "    y_df = dw.extend_df_for_crops_dividing(y_df, crop_size, crop_step)\n",
    "    dw.draw_defects_map(y_df, title=f'The part after extending for crop dividing')\n",
    "\n",
    "    x_arr = dw.df_to_numpy(x_df)\n",
    "    y_arr = y_df.to_numpy()\n",
    "    \n",
    "    x_arr_time = dw.standardize_data(x_arr[:,:,:32])\n",
    "    x_arr_amp = dw.standardize_data(x_arr[:,:,32:])\n",
    "    y_arr = dw.standardize_data(y_arr)\n",
    "    \n",
    "    x_arr_time_crops_gen = dw.get_augmented_crop_generator(x_arr_time, crop_size, crop_step)\n",
    "    x_arr_amp_crops_gen = dw.get_augmented_crop_generator(x_arr_amp, crop_size, crop_step)\n",
    "    \n",
    "    y_data_binary_gen = (1 if np.sum(crop > 0) else 0 for crop in \n",
    "                         dw.get_augmented_crop_generator(y_arr, crop_size, crop_step))\n",
    "    y_data_depth_gen = (np.max(crop) for crop in \n",
    "                        dw.get_augmented_crop_generator(y_arr, crop_size, crop_step))\n",
    "\n",
    "    logger.debug(\"end\")\n",
    "    return x_arr_time_crops_gen, x_arr_amp_crops_gen, y_data_binary_gen, y_data_depth_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6eed22-6c4d-4857-a2d6-56ebeacf52a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(train_x_time_gen1, \n",
    " train_x_amp_gen1, \n",
    " train_y_binary_gen1,\n",
    " train_y_depth_gen1) = get_dataset_gen(PATH_TO_DATA['run_1'], 200, DataCrop(None,None,200,None), CROP_SIZE, 20)\n",
    "\n",
    "(train_x_time_gen2, \n",
    " train_x_amp_gen2, \n",
    " train_y_binary_gen2,\n",
    " train_y_depth_gen2) = get_dataset_gen(PATH_TO_DATA['run_2'], 200, DataCrop(None,None,None,200), CROP_SIZE, 20)\n",
    "\n",
    "train_x_time = np.stack([crop for crop in itertools.chain(train_x_time_gen1, train_x_time_gen2)])\n",
    "train_x_amp = np.stack([crop for crop in itertools.chain(train_x_amp_gen1, train_x_amp_gen2)])\n",
    "train_y_binary = np.array([binary for binary in itertools.chain(train_y_binary_gen1, train_y_binary_gen2)])\n",
    "train_y_depth = np.array([depth for depth in itertools.chain(train_y_depth_gen1, train_y_depth_gen2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873ad11-5550-40e4-8fc5-7d005f73d7be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(val_x_time_gen, \n",
    " val_x_amp_gen, \n",
    " val_y_binary_gen,\n",
    " val_y_depth_gen) = get_dataset_gen(PATH_TO_DATA['run_1'], 200, DataCrop(None,None,None,200), CROP_SIZE, 20)\n",
    "\n",
    "val_x_time = np.stack([crop for crop in val_x_time_gen])\n",
    "val_x_amp = np.stack([crop for crop in val_x_amp_gen])\n",
    "val_y_binary = np.array([binary for binary in val_y_binary_gen])\n",
    "val_y_depth = np.array([depth for depth in val_y_depth_gen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2823cf-cb12-41f3-8f17-5674216fb80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{train_x_time.shape=}')\n",
    "print(f'{train_x_amp.shape=}')\n",
    "print(f'{train_y_binary.shape=}')\n",
    "print(f'{train_y_depth.shape=}')\n",
    "print()\n",
    "print(f'{val_x_time.shape=}')\n",
    "print(f'{val_x_amp.shape=}')\n",
    "print(f'{val_y_binary.shape=}')\n",
    "print(f'{val_y_depth.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d349042-3aea-460f-9ed8-fdd68be5b0a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# всякие константы для последующей работы\n",
    "\n",
    "#///////////////////////////////// для компиляции \n",
    "\n",
    "CMP_learning_rate = 0.0001 #0.0000002 # шаг сходимости back propogation\n",
    "#CMP_solver = keras.optimizers.Adam(CMP_learning_rate) # оптимизатор\n",
    "CMP_solver = keras.optimizers.SGD(CMP_learning_rate) # оптимизатор\n",
    "CMP_loss_funcs = keras.losses.BinaryCrossentropy() \n",
    "CMP_metrics = [keras.metrics.BinaryAccuracy(name='BinaryAccuracy'),\n",
    "               keras.metrics.MeanSquaredError(name='MeanSquaredError'),\n",
    "               keras.metrics.TruePositives(name='TruePositives'),\n",
    "               keras.metrics.FalsePositives(name='FalsePositives'),\n",
    "               keras.metrics.TrueNegatives(name='TrueNegatives'),\n",
    "               keras.metrics.FalseNegatives(name='FalseNegatives'),     \n",
    "               keras.metrics.Precision(name='Precision'),\n",
    "               keras.metrics.Recall(name='Recall'),\n",
    "               keras.metrics.AUC(name='AUC')]\n",
    "#///////////////////////////////// для колбэков\n",
    "\n",
    "'''    # для Early_stopping\n",
    "ES_patience = 3 # кол-во эпох без улучшений\n",
    "ES_min_delta = 0.00001 # минимальное улучшение параметра за cur_patience\n",
    "ES_monitor_parametr =  'loss' # отслеживаемый параметр \n",
    "ES_save_best_weights = True # сохранять ли веса нейронки с лучшими результатами\n",
    "    \n",
    "'''    # для ReduceLROnPlateau\n",
    "RLPOP_monitor_parametr = 'BinaryAccuracy'  # отслеживаемый параметр \n",
    "RLPOP_factor = 0.3 # множитель для расчета нового шага сходимости (new_learning_rate = old_learning_rate*RLPOP_factor)\n",
    "RLPOP_patience = 1 # кол-во эпох без улучшений\n",
    "RLPOP_verbose = 1 # выводить ли прогресс изменения шага сходимости в его процессее\n",
    "RLPOP_mode = 'auto' # выбирает, уменьшать шаг сходимости при росте величины или при её уменьшении\n",
    "RLPOP_min_delta = 0.0001 # порог изменения отслеживаемого значения\n",
    "RLPOP_cooldown = 2 # количество эпох до возобновления работы после изменения шага сходимости\n",
    "RLPOP_min_lr = 0 # минимальное значение шага сходимости\n",
    "\n",
    "    # для CallbackList\n",
    "CBL_add_history = True # вызывать ли колбэк History (если он не был довавлен вручную)\n",
    "CBL_add_progbar = True # вызывать ли колбэк ProgbarLogger (если он не был довавлен вручную)\n",
    "    \n",
    "#///////////////////////////////// для тренировки\n",
    "\n",
    "FIT_batch_size = 1 # размерpython concat lists bach при обучении/тестировании1\n",
    "#FIT_shuffle = True # перемешивать ли данные\n",
    "FIT_verbose = True # выводить ли прогресс обучения в его процессее\n",
    "FIT_epochs = 2 # количество эпох обучения\n",
    "#FIT_validation_split = 0.10 #0.20 # процент валидационных данных, отсекаемых из тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c53cc4-e675-4f9a-9dc8-372a514d4329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = mv.get_model_v10(CROP_SIZE)\n",
    "\n",
    "model.compile(optimizer=CMP_solver, loss=CMP_loss_funcs, metrics=CMP_metrics)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b38b9-92f4-4103-becf-71c82bde93a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=200,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04161a12-c245-4afd-83d2-2489ff29655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и настройка колбэков\n",
    "\n",
    "callback_list = [] # массив колбэков до подачи в колбек \"callbacklist\"\n",
    "\n",
    "'''temp = keras.callbacks.EarlyStopping(\n",
    "            monitor = ES_monitor_parametr, \n",
    "            min_delta = ES_min_delta, \n",
    "            patience = ES_patience,\n",
    "            restore_best_weights = ES_save_best_weights\n",
    "            )\n",
    "callback_list.append(temp)\n",
    "\n",
    "temp = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor = RLPOP_monitor_parametr, \n",
    "            factor = RLPOP_factor, \n",
    "            patience = RLPOP_patience, \n",
    "            verbose = RLPOP_verbose,\n",
    "            mode = RLPOP_mode, \n",
    "            min_delta = RLPOP_min_delta, \n",
    "            cooldown = RLPOP_cooldown, \n",
    "            min_lr = RLPOP_min_lr\n",
    "            )\n",
    "callback_list.append(temp)'''\n",
    "\n",
    "FIT_callback_list = keras.callbacks.CallbackList(\n",
    "            callbacks = callback_list, \n",
    "            add_history = CBL_add_history, \n",
    "            add_progbar = CBL_add_progbar, \n",
    "            model = model\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5597b1-1975-4d92-8489-d934de5c10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([train_x_time, train_x_amp], train_y_binary,\n",
    "                    batch_size = FIT_batch_size, \n",
    "                    epochs = FIT_epochs, \n",
    "                    verbose = FIT_verbose, \n",
    "                    shuffle=True,\n",
    "                    validation_data = ([val_x_time, val_x_amp], val_y_binary), \n",
    "                    callbacks = FIT_callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe431e-cba2-405e-8c7e-30506bd40576",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_SIZE = 15\n",
    "for key1,key2 in zip(['BinaryAccuracy','Precision','MeanSquaredError','TruePositives','TrueNegatives'],\n",
    "                     ['loss','Recall','AUC','FalseNegatives','FalsePositives']):\n",
    "    fig, axes = plt.subplots(1,2)\n",
    "\n",
    "    fig.set_figwidth(22)\n",
    "    fig.set_figheight(8)\n",
    "    \n",
    "    axes[0].plot(history.history[key1], \n",
    "             label='Train dataset',  linewidth=1.5, color='blue')\n",
    "    axes[0].plot(history.history[f'val_{key1}'], linestyle = '--', \n",
    "             label='Validation dataset',  linewidth=3, color='red')\n",
    "    axes[0].set_xlabel('Epoch number', fontsize=FONT_SIZE)\n",
    "    axes[0].set_ylabel(f'{key1} value', fontsize=FONT_SIZE)\n",
    "    axes[0].set_title(f\"Learning process {key1} plot\", fontsize=FONT_SIZE, pad=15)\n",
    "    axes[0].tick_params(axis='both', which='both', labelsize = FONT_SIZE)\n",
    "    axes[0].minorticks_on()\n",
    "    axes[0].grid(which='major', linewidth=2)\n",
    "    axes[0].grid(which='minor', color = 'gray', linestyle = ':')\n",
    "    axes[0].legend(fontsize = FONT_SIZE, facecolor = \"white\", loc = 'upper right')\n",
    "\n",
    "    axes[1].plot(history.history[key2], \n",
    "             label='Train dataset',  linewidth=1.5, color='blue')\n",
    "    axes[1].plot(history.history[f'val_{key2}'], linestyle = '--', \n",
    "             label='Validation dataset',  linewidth=3, color='red')\n",
    "    axes[1].set_xlabel('Epoch number', fontsize=FONT_SIZE)\n",
    "    axes[1].set_ylabel(f'{key2} value', fontsize=FONT_SIZE)\n",
    "    axes[1].set_title(f\"Learning process {key2} plot\", fontsize=FONT_SIZE, pad=15)\n",
    "    axes[1].tick_params(axis='both', which='both', labelsize = FONT_SIZE)\n",
    "    axes[1].minorticks_on()\n",
    "    axes[1].grid(which='major', linewidth=2)\n",
    "    axes[1].grid(which='minor', color = 'gray', linestyle = ':')\n",
    "    axes[1].legend(fontsize = FONT_SIZE, facecolor = \"white\", loc = 'upper right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd754500-4101-490c-8347-e28fbf679db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение модели в файл\n",
    "#model.save(f\"networks/CNN/id=v10n01_in(16x16+16x16)_out(1)_train=0dot0_test=0dot0.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615a1e2-0639-48a9-bb44-9356b4bd58c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''for key in [k for k in history.history.keys() if not k.startswith('val')]:\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    fig.set_figwidth(12)\n",
    "    fig.set_figheight(8)\n",
    "    \n",
    "    plt.plot(history.history[key], \n",
    "             label='Train dataset',  linewidth=1.5, color='blue')\n",
    "    plt.plot(history.history[f'val_{key}'], linestyle = '--', \n",
    "             label='Validation dataset',  linewidth=3, color='red')\n",
    "    \n",
    "    ax.set_xlabel('Epoch number', fontsize=20)\n",
    "    ax.set_ylabel(f'{key} value', fontsize=20)\n",
    "    ax.set_title(f\"Learning process {key} plot\", fontsize=20, pad=15)\n",
    "    \n",
    "    ax.patch.set_alpha(0)\n",
    "    \n",
    "    #  Устанавливаем форматирование делений:\n",
    "    ax.tick_params(axis='both', which='both', labelsize = 20)\n",
    "    \n",
    "    # Вывод и настройка сетки\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='major', linewidth=2)\n",
    "    ax.grid(which='minor', color = 'gray', linestyle = ':')\n",
    "    \n",
    "    ax.legend(fontsize = 20, facecolor = \"white\", loc = 'upper right')\n",
    "    \n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b3189-a635-46c3-9420-24717863c2b2",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
