{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde58157-7750-45b9-a343-b46e3c74b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies import\n",
    "from common_dependencies import *\n",
    "import model_versions as mv\n",
    "logger = logging.getLogger(f'main.model_train')\n",
    "# детерминация случайных величин, отвечающих за выбор первоначальных весов и биасов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf461c0-86ef-4815-a965-1e766c1f33b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train params that can be easily changed\n",
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)\n",
    "np.random.seed(290)\n",
    "CROP_SIZE = 16\n",
    "CROP_STEP = 1\n",
    "MAX_VAL = 1000\n",
    "XSHIFT = 200\n",
    "dataset_desc = {'train': (DatasetPartDescription(PATH_TO_DATA['run_1'],DataCrop(120,0,240,MAX_VAL),SlidingCrop(CROP_SIZE,CROP_STEP),XSHIFT)\n",
    "                          \n",
    "                         ,),\n",
    "                'val': (DatasetPartDescription(PATH_TO_DATA['run_1'],DataCrop(0,0,120,MAX_VAL),SlidingCrop(CROP_SIZE,CROP_STEP),XSHIFT),\n",
    "                        DatasetPartDescription(PATH_TO_DATA['run_1'],DataCrop(360,0,MAX_VAL,MAX_VAL),SlidingCrop(CROP_SIZE,CROP_STEP),XSHIFT),\n",
    "                        DatasetPartDescription(PATH_TO_DATA['run_2'],DataCrop(0,0,MAX_VAL,40),SlidingCrop(CROP_SIZE,CROP_STEP),XSHIFT)\n",
    "                        \n",
    "                        ,)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0b4af-ac01-4237-9e3e-5e9509ac97bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#входные и выходные данные\n",
    "# reading\n",
    "dataset = {'train':dict(zip(['x','y','bin'], [np.array(list(gen)) for gen in chain_dataset_gens(dataset_desc['train'])])),\n",
    "           'val':dict(zip(['x','y','bin'], [np.array(list(gen)) for gen in chain_dataset_gens(dataset_desc['val'])]))}\n",
    "\n",
    "# displaying\n",
    "logger.debug('Dataset')\n",
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    logger.debug('|'*8+dataset_part_name+'|'*8)\n",
    "    for data_part_name, data_part in dataset_part.items():\n",
    "        logger.debug(f'{data_part_name}.shape: {data_part.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e00ba-caa6-4a01-abfa-12819ced2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#выборка данных\n",
    "# show parts took for learning\n",
    "all_rects = {'run_1': {'train':None,'val':None}, \n",
    "             'run_2': {'train':None,'val':None}}\n",
    "rects_colors = {'train':'red', 'val':'green'}\n",
    "\n",
    "for run_name in all_rects.keys():\n",
    "    x_df, y_df = dw.get_x_and_y_data(*PATH_TO_DATA[run_name])\n",
    "    x_df = None\n",
    "    y_df = dw.roll_df(y_df, XSHIFT, 1)\n",
    "    for dataset_part_name in all_rects[run_name].keys():\n",
    "        # get all DatasetPartDescription for train, val or test\n",
    "        dataset_part_desc = dataset_desc[dataset_part_name]\n",
    "        # get all DatasetPartDescription for current run_name (run_1 or run_2)\n",
    "        dataset_part_desc = [dataset_part for dataset_part in dataset_part_desc if re.findall(r'run_\\d', dataset_part.data_path_tuple[0])[0] == run_name]\n",
    "        # put rects list to all_rects[run_name][dataset_part_name]\n",
    "        all_rects[run_name][dataset_part_name] = [Rectangle((dataset_part.file_data_crop.left, dataset_part.file_data_crop.top), \n",
    "                           dataset_part.file_data_crop.width, dataset_part.file_data_crop.height, \n",
    "                           facecolor=rects_colors[dataset_part_name], alpha=0.5) for dataset_part in dataset_part_desc]\n",
    "    res_rects = list(itertools.chain(*[run_rects for run_rects_name, run_rects in all_rects[run_name].items()]))\n",
    "    if res_rects:\n",
    "        dw.draw_defects_map_with_rectangles_owerlap(y_df, res_rects, title = f'The parts took for learning from run_1 (red - train, green - validate, other - test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4785ef8c-95c1-4479-9801-d035a2621fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### всякие константы для последующей работы\n",
    "\n",
    "#///////////////////////////////// для компиляции \n",
    "\n",
    "CMP_learning_rate = 0.005 #0.0000002 # шаг сходимости back propogation\n",
    "#CMP_solver = keras.optimizers.Adam(CMP_learning_rate) # оптимизатор\n",
    "CMP_solver = keras.optimizers.SGD(CMP_learning_rate) # оптимизатор\n",
    "CMP_loss_funcs = keras.losses.BinaryCrossentropy() #BinaryCrossentropy() \n",
    "CMP_metrics = [keras.metrics.BinaryAccuracy(name='BinaryAccuracy'),\n",
    "               keras.metrics.MeanSquaredError(name='MeanSquaredError'),\n",
    "               keras.metrics.TruePositives(name='TruePositives'),\n",
    "               keras.metrics.FalsePositives(name='FalsePositives'),\n",
    "               keras.metrics.TrueNegatives(name='TrueNegatives'),\n",
    "               keras.metrics.FalseNegatives(name='FalseNegatives'),     \n",
    "               keras.metrics.Precision(name='Precision'),\n",
    "               keras.metrics.Recall(name='Recall'),\n",
    "               keras.metrics.AUC(name='AUC')]\n",
    "#///////////////////////////////// для колбэков\n",
    "\n",
    "# для Early_stopping\n",
    "ES_patience = 3 # кол-во эпох без улучшений\n",
    "ES_min_delta = 0.00001 # минимальное улучшение параметра за cur_patience\n",
    "ES_monitor_parametr =  'loss' # отслеживаемый параметр \n",
    "ES_save_best_weights = True # сохранять ли веса нейронки с лучшими результатами\n",
    "Es_mode = 'max'\n",
    "\n",
    "   # для ReduceLROnPlateau\n",
    "RLPOP_monitor_parametr = 'loss'  # отслеживаемый параметр \n",
    "RLPOP_factor = 0.3 # множитель для расчета нового шага сходимости (new_learning_rate = old_learning_rate*RLPOP_factor)\n",
    "RLPOP_patience = 1 # кол-во эпох без улучшений\n",
    "RLPOP_verbose = 1 # выводить ли прогресс изменения шага сходимости в его процессее\n",
    "RLPOP_mode = 'auto' # выбирает, уменьшать шаг сходимости при росте величины или при её уменьшении\n",
    "RLPOP_min_delta = 0.001 # порог изменения отслеживаемого значения\n",
    "RLPOP_cooldown = 2 # количество эпох до возобновления работы после изменения шага сходимости\n",
    "RLPOP_min_lr = 0 # минимальное значение шага сходимости\n",
    "\n",
    "    # для CallbackList\n",
    "MODEL_VER = '14'\n",
    "MODEL_NUM = '03'\n",
    "MC_path = f\"networks/CNN/checkpoints/model_id=v{MODEL_VER}n{MODEL_NUM}\" + \"/check-{epoch:04d}.keras\"\n",
    "\n",
    "    # для CallbackList\n",
    "CBL_add_history = True # вызывать ли колбэк History (если он не был довавлен вручную)\n",
    "CBL_add_progbar = True # вызывать ли колбэк ProgbarLogger (если он не был довавлен вручную)\n",
    "    \n",
    "#///////////////////////////////// для тренировки\n",
    "\n",
    "FIT_batch_size = 4 # размерpython concat lists bach при обучении/тестировании1\n",
    "#FIT_shuffle = True # перемешивать ли данные\n",
    "FIT_verbose = True # выводить ли прогресс обучения в его процессее\n",
    "FIT_epochs = 5 #40 # количество эпох обучения\n",
    "#FIT_validation_split = 0.10 #0.20 # процент валидационных данных, отсекаемых из тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c53cc4-e675-4f9a-9dc8-372a514d4329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = mv.get_model_v10(CROP_SIZE)\n",
    "'''DROP = 0.1\n",
    "\n",
    "def bnorm(layer, drop_percent):\n",
    "    #return Dropout(drop_percent)(BatchNormalization()(layer))\n",
    "    return Dropout(drop_percent)(layer)\n",
    "    #return BatchNormalization()(layer)'''\n",
    "\n",
    "augment_data = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(1),\n",
    "  layers.RandomTranslation(0.4,0.4,fill_mode=\"reflect\"),\n",
    "  layers.RandomZoom(0.2,0.2,fill_mode=\"reflect\")\n",
    "])\n",
    ".to_excel\n",
    "input_data = Input((16,16,64), name = 'input_data')\n",
    "\n",
    "aug_data = augment_data(input_data)\n",
    "\n",
    "# 12\n",
    "dconv_1_1 = Conv2D(128, (3,3), dilation_rate=(2, 2), activation='relu', name='dconv_1_1')(aug_data)\n",
    "\n",
    "# 6\n",
    "dconv_1_2 = Conv2D(128, (3,3), dilation_rate=(5, 5), activation='relu', name='dconv_1_2')(aug_data)\n",
    "up_1_2 = UpSampling2D(2, interpolation='bilinear', name='up_1_2') (dconv_1_2)\n",
    "\n",
    "# 4\n",
    "dconv_1_3 = Conv2D(128, (3,3), dilation_rate=(6, 6), activation='relu', name='dconv_1_3')(aug_data)\n",
    "up_1_3 = UpSampling2D(3, interpolation='bilinear', name='up_1_3') (dconv_1_3)\n",
    "\n",
    "# 2\n",
    "dconv_1_4 = Conv2D(128, (3,3), dilation_rate=(7, 7), activation='relu', name='dconv_1_4')(aug_data)\n",
    "up_1_4 = UpSampling2D(6, interpolation='bilinear', name='up_1_4') (dconv_1_4)\n",
    "\n",
    "\n",
    "conc_1_1 = concatenate([dconv_1_1, up_1_2, up_1_3, up_1_4],axis=3, name='conc_1_1')\n",
    "\n",
    "\n",
    "conv_2_1 = Conv2D(512, (3,3), dilation_rate=(2, 2), activation='relu', padding='same', name='conv_2_1')(conc_1_1)\n",
    "conv_2_2 = Conv2D(512, (3,3), dilation_rate=(2, 2), activation='relu', padding='same', name='conv_2_2')(conv_2_1)\n",
    "conv_2_3 = Conv2D(512, (3,3), dilation_rate=(2, 2), activation='relu', padding='same', name='conv_2_3')(conv_2_2)\n",
    "pool_2_1 = MaxPooling2D((2,2), strides=2, name='pool_2_1')(conv_2_3)\n",
    "\n",
    "conv_2_4 = Conv2D(1024, (2,2), activation='relu', name='conv_2_4')(pool_2_1)\n",
    "conv_2_5 = Conv2D(1024, (2,2), activation='relu', name='conv_2_5')(conv_2_4)\n",
    "conv_2_6 = Conv2D(1024, (2,2), activation='relu', name='conv_2_6')(conv_2_5)\n",
    "conv_2_7 = Conv2D(1024, (2,2), activation='relu', name='conv_2_7')(conv_2_6)\n",
    "pool_2_2 = MaxPooling2D((2,2), strides=2, name='pool_2_2')(conv_2_7)\n",
    "\n",
    "d_4_1 = Dense(1024, activation='linear', name='d_4_1')(Flatten(name='flat_3_1')(pool_2_2))\n",
    "d_4_2 = Dense(512, activation='linear', name='d_4_2')(d_4_1)\n",
    "d_4_3 = Dense(256, activation='linear', name='d_4_3')(d_4_2)\n",
    "d_4_4 = Dense(128, activation='linear', name='d_4_4')(d_4_3)\n",
    "d_4_5 = Dense(64, activation='linear', name='d_4_5')(d_4_4)\n",
    "d_4_6 = Dense(16, activation='linear', name='d_4_6')(d_4_5)\n",
    "d_4_7 = Dense(4, activation='linear', name='d_4_7')(d_4_6)\n",
    "\n",
    "output_def_bool = Dense(1, activation='sigmoid', name='output_def_bool')(d_4_7)\n",
    "    \n",
    "model = keras.Model([input_data], [output_def_bool], name='model')\n",
    "\n",
    "#model = keras.models.load_model('networks/CNN/id=v13n01_in(16x16x64)_out(1)_train=0dot0_test=0dot0.keras')\n",
    "\n",
    "model.compile(optimizer=CMP_solver, loss=CMP_loss_funcs, metrics=CMP_metrics)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b38b9-92f4-4103-becf-71c82bde93a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=200,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04161a12-c245-4afd-83d2-2489ff29655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и настройка колбэков\n",
    "\n",
    "callback_list = [] # массив колбэков до подачи в колбек \"callbacklist\"\n",
    "\n",
    "'''\n",
    "callback_list.append(keras.callbacks.EarlyStopping(\n",
    "            monitor = ES_monitor_parametr, \n",
    "            min_delta = ES_min_delta, \n",
    "            patience = ES_patience,\n",
    "            restore_best_weights = ES_save_best_weights\n",
    "            ))'''\n",
    "\n",
    "callback_list.append(keras.callbacks.ModelCheckpoint(\n",
    "    MC_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch'))\n",
    "\n",
    "callback_list.append(keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor = RLPOP_monitor_parametr, \n",
    "            factor = RLPOP_factor, \n",
    "            patience = RLPOP_patience, \n",
    "            verbose = RLPOP_verbose,\n",
    "            mode = RLPOP_mode, \n",
    "            min_delta = RLPOP_min_delta, \n",
    "            cooldown = RLPOP_cooldown, \n",
    "            min_lr = RLPOP_min_lr\n",
    "            ))\n",
    "\n",
    "FIT_callback_list = keras.callbacks.CallbackList(\n",
    "            callbacks = callback_list, \n",
    "            add_history = CBL_add_history, \n",
    "            add_progbar = CBL_add_progbar, \n",
    "            model = model\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5597b1-1975-4d92-8489-d934de5c10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dataset['train']['x'], dataset['train']['bin'],\n",
    "                    batch_size = FIT_batch_size, \n",
    "                    epochs = FIT_epochs, \n",
    "                    verbose = FIT_verbose, \n",
    "                    shuffle=True,\n",
    "                    validation_data = (dataset['val']['x'], dataset['val']['bin']), \n",
    "                    callbacks = FIT_callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe431e-cba2-405e-8c7e-30506bd40576",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_SIZE = 15\n",
    "for key1,key2 in zip(['BinaryAccuracy','Precision','MeanSquaredError','TruePositives','TrueNegatives'],\n",
    "                     ['loss','Recall','AUC','FalseNegatives','FalsePositives']):\n",
    "    fig, axes = plt.subplots(1,2)\n",
    "\n",
    "    fig.set_figwidth(22)\n",
    "    fig.set_figheight(8)\n",
    "    \n",
    "    axes[0].plot(history.history[key1], \n",
    "             label='Train dataset',  linewidth=1.5, color='blue')\n",
    "    axes[0].plot(history.history[f'val_{key1}'], linestyle = '--', \n",
    "             label='Validation dataset',  linewidth=3, color='red')\n",
    "    axes[0].set_xlabel('Epoch number', fontsize=FONT_SIZE)\n",
    "    axes[0].set_ylabel(f'{key1} value', fontsize=FONT_SIZE)\n",
    "    axes[0].set_title(f\"Learning process {key1} plot\", fontsize=FONT_SIZE, pad=15)\n",
    "    axes[0].tick_params(axis='both', which='both', labelsize = FONT_SIZE)\n",
    "    axes[0].minorticks_on()\n",
    "    axes[0].grid(which='major', linewidth=2)\n",
    "    axes[0].grid(which='minor', color = 'gray', linestyle = ':')\n",
    "    axes[0].legend(fontsize = FONT_SIZE, facecolor = \"white\", loc = 'upper right')\n",
    "\n",
    "    axes[1].plot(history.history[key2], \n",
    "             label='Train dataset',  linewidth=1.5, color='blue')\n",
    "    axes[1].plot(history.history[f'val_{key2}'], linestyle = '--', \n",
    "             label='Validation dataset',  linewidth=3, color='red')\n",
    "    axes[1].set_xlabel('Epoch number', fontsize=FONT_SIZE)\n",
    "    axes[1].set_ylabel(f'{key2} value', fontsize=FONT_SIZE)\n",
    "    axes[1].set_title(f\"Learning process {key2} plot\", fontsize=FONT_SIZE, pad=15)\n",
    "    axes[1].tick_params(axis='both', which='both', labelsize = FONT_SIZE)\n",
    "    axes[1].minorticks_on()\n",
    "    axes[1].grid(which='major', linewidth=2)\n",
    "    axes[1].grid(which='minor', color = 'gray', linestyle = ':')\n",
    "    axes[1].legend(fontsize = FONT_SIZE, facecolor = \"white\", loc = 'upper right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615a1e2-0639-48a9-bb44-9356b4bd58c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''FONT_SIZE = 15\n",
    "for key in [k for k in history.history.keys() if not k.startswith('val')]:\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    fig.set_figwidth(12)\n",
    "    fig.set_figheight(8)\n",
    "    \n",
    "    plt.plot(history.history[key], \n",
    "             label='Train dataset',  linewidth=1.5, color='blue')\n",
    "    plt.plot(history.history[f'val_{key}'], linestyle = '--', \n",
    "             label='Validation dataset',  linewidth=3, color='red')\n",
    "    \n",
    "    ax.set_xlabel('Epoch number', fontsize=FONT_SIZE)\n",
    "    ax.set_ylabel(f'{key} value', fontsize=FONT_SIZE)\n",
    "    ax.set_title(f\"Learning process {key} plot\", fontsize=FONT_SIZE, pad=15)\n",
    "    \n",
    "    ax.patch.set_alpha(0)\n",
    "    \n",
    "    #  Устанавливаем форматирование делений:\n",
    "    ax.tick_params(axis='both', which='both', labelsize = FONT_SIZE)\n",
    "    \n",
    "    # Вывод и настройка сетки\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='major', linewidth=2)\n",
    "    ax.grid(which='minor', color = 'gray', linestyle = ':')\n",
    "    \n",
    "    ax.legend(fontsize = FONT_SIZE, facecolor = \"white\", loc = 'upper right')\n",
    "    \n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd754500-4101-490c-8347-e28fbf679db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранинеи процесса обучения в файл\n",
    "learn_df = pd.DataFrame.from_dict(history.history)\n",
    "learn_df.to_excel(f\"networks/CNN/checkpoints/model_id=v{MODEL_VER}n{MODEL_NUM}/learning_df.xlsx\")\n",
    "# сохранение модели в файл\n",
    "model.save(f\"networks/CNN/id=v{MODEL_VER}n{MODEL_NUM}_in({CROP_SIZE}x{CROP_SIZE}x64)_out(1)_train=0dot0_test=0dot0.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b3189-a635-46c3-9420-24717863c2b2",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
