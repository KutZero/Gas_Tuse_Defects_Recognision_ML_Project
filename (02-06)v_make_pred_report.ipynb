{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc8322-9ef3-4f86-8fcb-e98e541c6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies import\n",
    "from common_dependencies import *\n",
    "\n",
    "from matplotlib import ticker\n",
    "from matplotlib.patches import Polygon as mplPolygon\n",
    "from shapely.geometry import Polygon as shPolygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "from docx.enum.section import WD_ORIENT\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Cm\n",
    "from docx.shared import Pt\n",
    "from docx.shared import RGBColor\n",
    "\n",
    "from typing import NamedTuple\n",
    "import logging\n",
    "logger = logging.getLogger('main.(02-06)v_make_pred_report.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d93ae-e033-4ee0-a8cd-f52879c23640",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_GET_DATA = 'data/drawing_data'\n",
    "PATH_TO_SAVE_DATA = 'data/report'\n",
    "MODEL_VERS = ['06'] # для каких версий моделей делать отчет\n",
    "MODEL_NUMS = ['01'] # для каких номеров моделей делать отчет\n",
    "CALC_LOSS_USING_DEFECT_DEPTH = False\n",
    "\n",
    "model_runs = r'\\d{2}' if len(MODEL_VERS) == 0 else f\"({'|'.join([model_ver for model_ver in MODEL_VERS])})\"\n",
    "model_nums = r'\\d{2}' if len(MODEL_NUMS) == 0 else f\"({'|'.join([model_num for model_num in MODEL_NUMS])})\"\n",
    "# пути к каким версиям и номерам моделей учитывать при создании отчетов\n",
    "model_folder_regex = r'.*/model_id=' + f'v{model_runs}n{model_nums}$'\n",
    "run_folder_regex = model_folder_regex[:-1] + r'/run_\\d+$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939c881-0731-4b3e-84ec-0e694dab4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrease_blur(df_cell_value):\n",
    "    res = 2*df_cell_value**2 if df_cell_value <= 0.5 else 1-(2*(1-df_cell_value)**2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb848a4e-6108-457e-bb1f-092b21f9c8ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create temp folder \"report\" in 'PATH_TO_DATA' parent folder\n",
    "# with identical folder tree structure as 'PATH_TO_DATA'\n",
    "# and fill every folder with jpgs instead of .xlsx files\n",
    "\n",
    "# BLUR ONES\n",
    "\n",
    "for run_path in os.walk(PATH_TO_GET_DATA):\n",
    "    ref = True\n",
    "    if re.match(run_folder_regex, run_path[0]) is None:\n",
    "        continue\n",
    "\n",
    "    full_path_to_save_run_files = run_path[0].replace(PATH_TO_GET_DATA, PATH_TO_SAVE_DATA)\n",
    "    \n",
    "    if not os.path.exists(full_path_to_save_run_files):\n",
    "        os.makedirs(full_path_to_save_run_files)\n",
    "    \n",
    "    logger.debug('Current working path: ' + run_path[0])\n",
    "    for file_name in run_path[2]:\n",
    "        if re.match('.*\\.xlsx', file_name) is None:\n",
    "            continue\n",
    "        logger.debug(file_name + ' processing...')\n",
    "\n",
    "        file_name = file_name.replace('.xlsx','')\n",
    "\n",
    "        ref_df = pd.read_excel(os.path.join(run_path[0], file_name + '.xlsx'),\n",
    "             sheet_name='orig_size_reference', index_col=0, dtype=np.float64)\n",
    "        ref_df = pd.DataFrame(data=dw.normalize_data(ref_df.to_numpy()), \n",
    "            index=ref_df.index, columns=ref_df.columns)\n",
    "        \n",
    "        pred_df = pd.read_excel(os.path.join(run_path[0], file_name + '.xlsx'),\n",
    "            sheet_name='orig_size_result', index_col=0, dtype=np.float64)\n",
    "        pred_df = pd.DataFrame(data=dw.normalize_data(pred_df.to_numpy()), \n",
    "            index=pred_df.index, columns=pred_df.columns)\n",
    "\n",
    "        \n",
    "        dw.draw_defects_map(ref_df, \n",
    "            title = 'REFERENCE ' + re.findall(r\"(model_id=v\\d{2}n\\d{2})\", file_name)[0],\n",
    "            path_to_save = os.path.join(full_path_to_save_run_files, f'REFERENCE {file_name}.jpg'))\n",
    "\n",
    "        dw.draw_defects_map(pred_df, \n",
    "            title = f'PREDICTION {file_name}',\n",
    "            path_to_save = os.path.join(full_path_to_save_run_files,\n",
    "                f'PREDICTION {file_name}_loss(use_depth={CALC_LOSS_USING_DEFECT_DEPTH}' +\n",
    "                f',value={dw.calc_model_prediction_accuracy(pred_df, ref_df, CALC_LOSS_USING_DEFECT_DEPTH):.4f}).jpg'))\n",
    "\n",
    "        dw.draw_defects_map_with_reference_owerlap(pred_df, ref_df, \n",
    "            title = f'OVERLAPPED PREDICTION {file_name}',\n",
    "            path_to_save = os.path.join(full_path_to_save_run_files,\n",
    "                f'OVERLAPPED PREDICTION {file_name}_loss(use_depth={CALC_LOSS_USING_DEFECT_DEPTH}' + \n",
    "                f',value={dw.calc_model_prediction_accuracy(pred_df, ref_df, CALC_LOSS_USING_DEFECT_DEPTH):.4f}).jpg'))\n",
    "\n",
    "        \n",
    "        unblur_pred_df = pred_df.map(decrease_blur)\n",
    "\n",
    "        dw.draw_defects_map(unblur_pred_df, \n",
    "            title = f'UNBLUR PREDICTION {file_name}',\n",
    "            path_to_save = os.path.join(full_path_to_save_run_files,\n",
    "                f'UNBLUR PREDICTION {file_name}_loss(use_depth={CALC_LOSS_USING_DEFECT_DEPTH}' + \n",
    "                f',value={dw.calc_model_prediction_accuracy(unblur_pred_df, ref_df, CALC_LOSS_USING_DEFECT_DEPTH):.4f}).jpg'))\n",
    "     \n",
    "        dw.draw_defects_map_with_reference_owerlap(unblur_pred_df, ref_df, \n",
    "            title = 'UNBLUR OVERLAPPED PREDICTION ' + file_name,\n",
    "            path_to_save = os.path.join(full_path_to_save_run_files,\n",
    "                f'UNBLUR OVERLAPPED PREDICTION {file_name}_loss(use_depth={CALC_LOSS_USING_DEFECT_DEPTH}' + \n",
    "                f',value={dw.calc_model_prediction_accuracy(unblur_pred_df, ref_df, CALC_LOSS_USING_DEFECT_DEPTH):.4f}).jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2c1f2c-8a9e-4909-bc9c-4688fe855466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ImageDescription = NamedTuple(\"ImageDescription\", \n",
    "                                  [('model_id', str), \n",
    "                                   ('run_num', int),\n",
    "                                   ('image_type_name', str),\n",
    "                                   ('crop_step', int),\n",
    "                                   ('path', str),\n",
    "                                   ('loss', float)])\n",
    "image_descriptions_list = []\n",
    "\n",
    "\n",
    "for run_path in os.walk(PATH_TO_SAVE_DATA):\n",
    "    if re.search(run_folder_regex, run_path[0]) is None:\n",
    "        continue\n",
    "    model_id = re.findall(r'model_id=(v\\d{2}n\\d{2})', run_path[0])[0]\n",
    "    run_num = re.findall(r'run_(\\d+)', run_path[0])[0]\n",
    "    for image_name in os.listdir(run_path[0]):\n",
    "        if re.match('.*\\.jpg', image_name) is None:\n",
    "            continue\n",
    "\n",
    "        crop_step = re.findall(r'step=(\\d+)', image_name)[0]\n",
    "        \n",
    "        image_type_name = re.search(r'[A-Z\\s]+', image_name)[0].strip()\n",
    "        if not image_type_name == 'REFERENCE':\n",
    "            loss = re.findall(r'value=(\\d+\\.\\d+)', image_name)[0]\n",
    "        else:\n",
    "            loss = ''\n",
    "        image_descriptions_list.append(ImageDescription(model_id, \n",
    "                                                        int(run_num), \n",
    "                                                        image_type_name, \n",
    "                                                        int(crop_step),\n",
    "                                                        os.path.join(run_path[0], image_name),\n",
    "                                                        loss))\n",
    "        #logger.debug(os.path.join(run_path[0], image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab90ebf-1a3e-4578-97ef-43af249ccd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 8\n",
    "for model_path in os.walk(PATH_TO_SAVE_DATA):\n",
    "    if re.match(model_folder_regex, model_path[0]) is None:\n",
    "        continue\n",
    "    model_id = re.findall(r'model_id=(v\\d{2}n\\d{2})', model_path[0])[0]\n",
    "    # images related to current model\n",
    "    model_images = [image_desc for image_desc in image_descriptions_list if image_desc.model_id == model_id]\n",
    "    # numbers of \"run_\"\n",
    "    run_numbers = list(set([image_desc.run_num for image_desc in model_images]))\n",
    "    run_numbers.sort()\n",
    "    \n",
    "    document = Document()\n",
    "    document.add_heading(f'MODEL_ID={model_id} PREDICTION RESULTS', 0)\n",
    "\n",
    "    for run in run_numbers:\n",
    "        ref_image = [image_desc for image_desc in model_images \n",
    "                     if image_desc.run_num == run and image_desc.image_type_name == 'REFERENCE']\n",
    "\n",
    "        \n",
    "        pred_images = [image_desc for image_desc in model_images \n",
    "                     if image_desc.run_num == run and image_desc.image_type_name == 'PREDICTION']\n",
    "        pred_images.sort(key=lambda x: x.crop_step, reverse=True)\n",
    "\n",
    "        unblur_pred_images = [image_desc for image_desc in model_images \n",
    "                 if image_desc.run_num == run and image_desc.image_type_name == 'UNBLUR PREDICTION']\n",
    "        unblur_pred_images.sort(key=lambda x: x.crop_step, reverse=True)\n",
    "\n",
    "        \n",
    "        overlapped_pred_images = [image_desc for image_desc in model_images \n",
    "                     if image_desc.run_num == run and image_desc.image_type_name == 'OVERLAPPED PREDICTION']\n",
    "        overlapped_pred_images.sort(key=lambda x: x.crop_step, reverse=True)\n",
    "\n",
    "        unblur_overlapped_pred_images = [image_desc for image_desc in model_images \n",
    "                     if image_desc.run_num == run and image_desc.image_type_name == 'UNBLUR OVERLAPPED PREDICTION']\n",
    "        unblur_overlapped_pred_images.sort(key=lambda x: x.crop_step, reverse=True)\n",
    "        \n",
    "        document.add_heading(f'RUN {run}', 1)\n",
    "        document.add_heading('REFERENCE', 2)\n",
    "        document.add_picture(ref_image[0].path, width=Inches(IMAGE_WIDTH))\n",
    "                    \n",
    "        document.add_heading('MODEL PREDICTION', 2)\n",
    "        for image_desc in pred_images:\n",
    "            document.add_picture(image_desc.path, width=Inches(IMAGE_WIDTH))\n",
    "\n",
    "        document.add_heading('UNBLUR MODEL PREDICTION', 2)\n",
    "        for image_desc in unblur_pred_images:\n",
    "            document.add_picture(image_desc.path, width=Inches(IMAGE_WIDTH))\n",
    "        \n",
    "        document.add_heading('OVERLAPPED WITH REFERENCE MODEL PREDICTION', 2)\n",
    "        for image_desc in overlapped_pred_images:\n",
    "            document.add_picture(image_desc.path, width=Inches(IMAGE_WIDTH))\n",
    "\n",
    "        document.add_heading('UNBLUR OVERLAPPED WITH REFERENCE MODEL PREDICTION', 2)\n",
    "        for image_desc in unblur_overlapped_pred_images:\n",
    "            document.add_picture(image_desc.path, width=Inches(IMAGE_WIDTH))\n",
    "        \n",
    "        document.add_page_break()\n",
    "        \n",
    "    section = document.sections[-1]\n",
    "    \n",
    "    #new_width, new_height = section.page_height, section.page_width\n",
    "    #section.orientation = WD_ORIENT.LANDSCAPE\n",
    "    #section.page_width = new_width\n",
    "    #section.page_height = new_height\n",
    "    \n",
    "    section.top_margin = Cm(0.5)\n",
    "    section.bottom_margin = Cm(0.5)\n",
    "    section.left_margin = Cm(0.5)\n",
    "    section.right_margin = Cm(0.5)\n",
    "\n",
    "    head0_style = document.styles['Title']\n",
    "    head1_style = document.styles['Heading 1']\n",
    "    head2_style = document.styles['Heading 2']\n",
    "\n",
    "    head0_style.font.size = Pt(24)\n",
    "    head1_style.font.size = Pt(22)\n",
    "    head2_style.font.size = Pt(20)\n",
    "    \n",
    "    head0_style.font.color.rgb = RGBColor(255, 0, 0)\n",
    "    head1_style.font.color.rgb = RGBColor(255, 0, 0)\n",
    "    head2_style.font.color.rgb = RGBColor(255, 0, 0)\n",
    "    \n",
    "    document.save(os.path.join(model_path[0], 'report.docx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aafa097-de10-4b62-b33e-ba651e42f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 8\n",
    "for model_path in os.walk(PATH_TO_SAVE_DATA):\n",
    "    if re.match(model_folder_regex, model_path[0]) is None:\n",
    "        continue\n",
    "    model_id = re.findall(r'model_id=(v\\d{2}n\\d{2})', model_path[0])[0]\n",
    "    # images related to current model\n",
    "    model_images = [image_desc for image_desc in image_descriptions_list if image_desc.model_id == model_id]\n",
    "    # numbers of \"run_\"\n",
    "    run_numbers = list(set([image_desc.run_num for image_desc in model_images]))\n",
    "    run_numbers.sort()\n",
    "    \n",
    "    document = Document()\n",
    "    document.add_heading(f'MODEL_ID={model_id} LOSSES', 0)\n",
    "\n",
    "    for run in run_numbers:\n",
    "        ref_image = [image_desc for image_desc in model_images \n",
    "                     if image_desc.run_num == run and image_desc.image_type_name == 'REFERENCE']\n",
    "        \n",
    "        pred_images = [image_desc for image_desc in model_images \n",
    "                     if image_desc.run_num == run and image_desc.image_type_name == 'PREDICTION']\n",
    "        pred_images.sort(key=lambda x: x.crop_step, reverse=True)\n",
    "\n",
    "        unblur_pred_images = [image_desc for image_desc in model_images \n",
    "                 if image_desc.run_num == run and image_desc.image_type_name == 'UNBLUR PREDICTION']\n",
    "        unblur_pred_images.sort(key=lambda x: x.crop_step, reverse=True)\n",
    "\n",
    "        losses = [image_desc.loss for image_desc in pred_images]\n",
    "        crop_steps = [image_desc.crop_step for image_desc in pred_images]\n",
    "\n",
    "        unblur_losses = [image_desc.loss for image_desc in unblur_pred_images]\n",
    "        unblur_crop_steps = [image_desc.crop_step for image_desc in unblur_pred_images]\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_figwidth(18)\n",
    "        fig.set_figheight(8)\n",
    "\n",
    "        plt.plot(crop_steps, losses, \n",
    "                 label='Raw prediction loss',  linewidth=1.5, color='blue')\n",
    "        plt.plot(unblur_crop_steps, unblur_losses,  \n",
    "                 label='Unblur prediction loss',  linewidth=3, color='red')\n",
    "        \n",
    "        ax.set_xlabel('Шаг нарезки кропов', fontsize=20)\n",
    "        ax.set_ylabel('Значение функции ошибки', fontsize=20)\n",
    "        ax.set_title(f\"График значений функции ошибки от шара нарезки кропов\", fontsize=20, pad=15)\n",
    "        \n",
    "        ax.patch.set_alpha(0)\n",
    "        \n",
    "        #  Устанавливаем форматирование делений:\n",
    "        ax.tick_params(axis='both', which='both', labelsize = 20)\n",
    "    \n",
    "        for loss, crop_size in zip(losses, crop_steps):\n",
    "            ax.text(crop_size, loss, str(loss), size=15, ha=\"center\")\n",
    "\n",
    "        for loss, crop_size in zip(unblur_losses, unblur_crop_steps):\n",
    "            ax.text(crop_size, loss, str(loss), size=15, ha=\"center\")\n",
    "        \n",
    "        # Вывод и настройка сетки\n",
    "        ax.minorticks_on()\n",
    "        ax.grid(which='major', linewidth=2)\n",
    "        ax.grid(which='minor', color = 'gray', linestyle = ':')\n",
    "        ax.legend(fontsize = 20, facecolor = \"white\", loc = 'upper right')\n",
    "        \n",
    "        plt.savefig(os.path.join(model_path[0], f'run_{run} losses graph.jpg'), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        document.add_heading(f'RUN {run}', 0)\n",
    "        document.add_picture(os.path.join(model_path[0], f'run_{run} losses graph.jpg'), width=Inches(IMAGE_WIDTH))\n",
    "        \n",
    "    section = document.sections[-1]\n",
    "    \n",
    "    #new_width, new_height = section.page_height, section.page_width\n",
    "    #section.orientation = WD_ORIENT.LANDSCAPE\n",
    "    #section.page_width = new_width\n",
    "    #section.page_height = new_height\n",
    "    \n",
    "    section.top_margin = Cm(0.5)\n",
    "    section.bottom_margin = Cm(0.5)\n",
    "    section.left_margin = Cm(0.5)\n",
    "    section.right_margin = Cm(0.5)\n",
    "\n",
    "    head0_style = document.styles['Title']\n",
    "    head1_style = document.styles['Heading 1']\n",
    "    head2_style = document.styles['Heading 2']\n",
    "\n",
    "    head0_style.font.size = Pt(24)\n",
    "    head1_style.font.size = Pt(22)\n",
    "    head2_style.font.size = Pt(20)\n",
    "    \n",
    "    head0_style.font.color.rgb = RGBColor(255, 0, 0)\n",
    "    head1_style.font.color.rgb = RGBColor(255, 0, 0)\n",
    "    head2_style.font.color.rgb = RGBColor(255, 0, 0)\n",
    "    \n",
    "    document.save(os.path.join(model_path[0], 'short_report.docx'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
