{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700e9457-0887-469b-830b-6f7396be6f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T15:02:30.600099Z",
     "iopub.status.busy": "2024-03-23T15:02:30.599986Z",
     "iopub.status.idle": "2024-03-23T15:02:32.614916Z",
     "shell.execute_reply": "2024-03-23T15:02:32.614611Z",
     "shell.execute_reply.started": "2024-03-23T15:02:30.600087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 22:02:31.032716: E external/local_xla/xla/stream_executor/plugin_registry.cc:91] Invalid plugin kind specified: FFT\n",
      "2024-03-23 22:02:31.072517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-23 22:02:31.531176: E external/local_xla/xla/stream_executor/plugin_registry.cc:91] Invalid plugin kind specified: DNN\n"
     ]
    }
   ],
   "source": [
    "# dependencies import\n",
    "from common_dependencies import *\n",
    "import logging\n",
    "logger = logging.getLogger('main.(02-05)v_make_pred.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34591ee-be65-42f8-8e4b-a8d2f49cee7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T15:02:32.615474Z",
     "iopub.status.busy": "2024-03-23T15:02:32.615295Z",
     "iopub.status.idle": "2024-03-23T15:02:32.618806Z",
     "shell.execute_reply": "2024-03-23T15:02:32.618564Z",
     "shell.execute_reply.started": "2024-03-23T15:02:32.615464Z"
    }
   },
   "outputs": [],
   "source": [
    "# paths for files with original data\n",
    "PATH_TO_DATA = {\n",
    "    'run_1': \n",
    "        ('data/original_data/run_1/run1_WM32_data.csv',\n",
    "        'data/original_data/run_1/run1_WM32_defects.csv',\n",
    "        'data/original_data/run_1/run1_WM32_pipe.csv'),\n",
    "    'run_2':\n",
    "        ('data/original_data/run_2/run2_WM32_data.csv',\n",
    "        'data/original_data/run_2/run2_WM32_defects.csv',\n",
    "        'data/original_data/run_2/run2_WM32_pipe.csv')\n",
    "}\n",
    "\n",
    "def get_quadratic_sequence(max_val: int, res_list: list[int] = [4]) -> list[int]:\n",
    "    if max_val % 2 == 1:\n",
    "        raise ValueError('max_val should be integer divisible by 2')\n",
    "        \n",
    "    if max(res_list) == max_val:\n",
    "        return res_list\n",
    "    res_list.append(max(res_list) * 2)\n",
    "    return get_quadratic_sequence(max_val, res_list)\n",
    "\n",
    "\n",
    "PATH_TO_MODEL = 'networks/CNN'\n",
    "RUNS = [1, 2]\n",
    "MODEL_VER = '09'\n",
    "MODEL_NUM = '03'\n",
    "XSHIFT = 200\n",
    "\n",
    "for name in os.listdir(PATH_TO_MODEL):\n",
    "    res = re.match(F'(id=v{MODEL_VER}n{MODEL_NUM}).*', name)\n",
    "    if not res is None:\n",
    "        PATH_TO_MODEL += '/' + res[0]\n",
    "        break\n",
    "\n",
    "# детерминация случайных величин, отвечающих за выбор первоначальных весов и биасов\n",
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad3135c-1cb6-4061-b326-664c758c1944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T15:02:32.619515Z",
     "iopub.status.busy": "2024-03-23T15:02:32.619405Z",
     "iopub.status.idle": "2024-03-23T15:02:35.939249Z",
     "shell.execute_reply": "2024-03-23T15:02:35.938919Z",
     "shell.execute_reply.started": "2024-03-23T15:02:32.619506Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 22:02:32.907160: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 22:02:32.942442: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 22:02:32.942503: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 22:02:32.943950: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 22:02:32.944044: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 22:02:32.944087: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 22:02:32.944162: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 22:02:32.944204: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 22:02:32.944220: E tensorflow/core/common_runtime/gpu/gpu_process_state.cc:81] TF_GPU_ALLOCATOR=cuda_malloc_async environment found, but TensorFlow was not compiled with CUDA 11.2+.\n",
      "2024-03-23 22:02:32.944254: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-23 22:02:32.944274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19386 MB memory:  -> device: 0, name: Radeon RX 7900 XT, pci bus id: 0000:08:00.0\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели\n",
    "load_model = keras.models.load_model(PATH_TO_MODEL)\n",
    "CROP_SIZE = load_model.inputs[0].shape[1]\n",
    "CROP_STEPS = get_quadratic_sequence(CROP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d194db4d-2777-4eff-80b9-cd61937abe9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T15:02:35.939786Z",
     "iopub.status.busy": "2024-03-23T15:02:35.939676Z",
     "iopub.status.idle": "2024-03-23T15:02:35.943954Z",
     "shell.execute_reply": "2024-03-23T15:02:35.943675Z",
     "shell.execute_reply.started": "2024-03-23T15:02:35.939776Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pred_fast(model, \n",
    "                   path_to_data_tuple: tuple(),\n",
    "                   x_shift: int,\n",
    "                   crop_size: int, \n",
    "                   crop_step: int):\n",
    "\n",
    "    # read data and roll dfs along x axis\n",
    "    x_df, y_df = dw.get_x_and_y_data(*path_to_data_tuple)\n",
    "    x_df = dw.roll_df(x_df, x_shift, axis=1)\n",
    "    y_df = dw.roll_df(y_df, x_shift, axis=1)\n",
    "\n",
    "    # save the read df shape\n",
    "    or_rows = x_df.shape[0]\n",
    "    or_cols = x_df.shape[1]\n",
    "\n",
    "    # extend x and y dfs for prediction and crops dividing\n",
    "    ex_x_df = dw.extend_df_for_prediction(x_df, crop_size)\n",
    "    ex_x_df = dw.extend_df_for_crops_dividing(ex_x_df, crop_size, crop_step)\n",
    "    ex_y_df = dw.extend_df_for_prediction(y_df, crop_size)\n",
    "    ex_y_df = dw.extend_df_for_crops_dividing(ex_y_df, crop_size, crop_step)\n",
    "\n",
    "    ex_rows = ex_x_df.shape[0]\n",
    "    ex_cols = ex_x_df.shape[1]\n",
    "\n",
    "    # reshape x df to set of crops\n",
    "    (x_data_time,\n",
    "    x_data_amp) = dw.reshape_x_df_to_image_like_numpy(ex_x_df, crop_size, crop_step)\n",
    "\n",
    "    # standardize x data\n",
    "    x_data_time = dw.standardize_data(x_data_time)\n",
    "    x_data_amp = dw.standardize_data(x_data_amp)\n",
    "    \n",
    "    res = model.predict([x_data_time, x_data_amp])[:,0]\n",
    "    res_it = iter(res)\n",
    "    \n",
    "    extend_size_arr = np.ones((ex_rows, ex_cols))     \n",
    "    for j in range(0,  ex_cols - crop_size + 1, crop_step):\n",
    "        for i in range(0, ex_rows - crop_size + 1, crop_step):  \n",
    "            temp_add = next(res_it)\n",
    "            if temp_add >= 0.5:\n",
    "                extend_size_arr[i:i+crop_size, j:j+crop_size] += temp_add\n",
    "            else:\n",
    "                extend_size_arr[i:i+crop_size, j:j+crop_size] -= temp_add \n",
    "    \n",
    "    orig_size_arr = extend_size_arr[crop_size - 1:, crop_size - 1:][:or_rows, :or_cols]\n",
    "\n",
    "    extend_size_result_df = pd.DataFrame(data=extend_size_arr, \n",
    "                             columns=ex_x_df.columns, \n",
    "                             index=ex_x_df.index)\n",
    "\n",
    "    orig_size_result_df = pd.DataFrame(data=orig_size_arr, \n",
    "                       columns=x_df.columns.tolist(), \n",
    "                       index=x_df.index.tolist())\n",
    "    \n",
    "    return orig_size_result_df, extend_size_result_df, y_df, ex_y_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5bc6ea9-3f1e-44a6-8a24-7d05b95722ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T15:02:35.944408Z",
     "iopub.status.busy": "2024-03-23T15:02:35.944308Z",
     "iopub.status.idle": "2024-03-23T15:03:29.719767Z",
     "shell.execute_reply": "2024-03-23T15:03:29.719420Z",
     "shell.execute_reply.started": "2024-03-23T15:02:35.944398Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.(02-05)v_make_pred.ipynb ::             <module>() :: run: 1, crop step: 4\n",
      "main.custom_modules.data_worker.data_worker ::     get_x_and_y_data() :: \n",
      "    Read detectors data shape: (115, 400)\n",
      "    Read defect data shape: (115, 400)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (145, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (145, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (148, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 4\n",
      "    The output df shape: (148, 432)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (145, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (145, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (148, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 4\n",
      "    The output df shape: (148, 432)\n",
      "main.custom_modules.data_worker.data_worker :: reshape_x_df_to_image_like_numpy() :: \n",
      "    The input df shape: (148, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 4\n",
      "    The output time array of crops shape: (3570, 16, 16, 32)\n",
      "    The output amplitude array of crops shape: (3570, 16, 16, 32)\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 44.5\n",
      "    The arr min before standardization: 0.0\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: 0.0\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 62.992\n",
      "    The arr min before standardization: -61.968\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: -0.983743967487935\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711206163.006019    8852 service.cc:145] XLA service 0x75d624002a10 initialized for platform ROCM (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1711206163.006047    8852 service.cc:153]   StreamExecutor device (0): Radeon RX 7900 XT, AMDGPU ISA version: gfx1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  8/112\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1711206165.739825    8852 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.(02-05)v_make_pred.ipynb ::             <module>() :: run: 1, crop step: 8\n",
      "main.custom_modules.data_worker.data_worker ::     get_x_and_y_data() :: \n",
      "    Read detectors data shape: (115, 400)\n",
      "    Read defect data shape: (115, 400)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (145, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (145, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (152, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 8\n",
      "    The output df shape: (152, 432)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (145, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (145, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (152, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 8\n",
      "    The output df shape: (152, 432)\n",
      "main.custom_modules.data_worker.data_worker :: reshape_x_df_to_image_like_numpy() :: \n",
      "    The input df shape: (152, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 8\n",
      "    The output time array of crops shape: (954, 16, 16, 32)\n",
      "    The output amplitude array of crops shape: (954, 16, 16, 32)\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 44.5\n",
      "    The arr min before standardization: 0.0\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: 0.0\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 62.992\n",
      "    The arr min before standardization: -61.968\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: -0.983743967487935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.(02-05)v_make_pred.ipynb ::             <module>() :: run: 1, crop step: 16\n",
      "main.custom_modules.data_worker.data_worker ::     get_x_and_y_data() :: \n",
      "    Read detectors data shape: (115, 400)\n",
      "    Read defect data shape: (115, 400)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (145, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (145, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (160, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 16\n",
      "    The output df shape: (160, 432)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (145, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (145, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (160, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 16\n",
      "    The output df shape: (160, 432)\n",
      "main.custom_modules.data_worker.data_worker :: reshape_x_df_to_image_like_numpy() :: \n",
      "    The input df shape: (160, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 16\n",
      "    The output time array of crops shape: (270, 16, 16, 32)\n",
      "    The output amplitude array of crops shape: (270, 16, 16, 32)\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 44.5\n",
      "    The arr min before standardization: 0.0\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: 0.0\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 62.992\n",
      "    The arr min before standardization: -61.968\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: -0.983743967487935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 299ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.(02-05)v_make_pred.ipynb ::             <module>() :: run: 2, crop step: 4\n",
      "main.custom_modules.data_worker.data_worker ::     get_x_and_y_data() :: \n",
      "    Read detectors data shape: (119, 400)\n",
      "    Read defect data shape: (119, 400)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (149, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (149, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (152, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 4\n",
      "    The output df shape: (152, 432)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (149, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (149, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (152, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 4\n",
      "    The output df shape: (152, 432)\n",
      "main.custom_modules.data_worker.data_worker :: reshape_x_df_to_image_like_numpy() :: \n",
      "    The input df shape: (152, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 4\n",
      "    The output time array of crops shape: (3675, 16, 16, 32)\n",
      "    The output amplitude array of crops shape: (3675, 16, 16, 32)\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 44.4\n",
      "    The arr min before standardization: 0.0\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: 0.0\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 62.992\n",
      "    The arr min before standardization: -62.482\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: -0.9919037338074677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.(02-05)v_make_pred.ipynb ::             <module>() :: run: 2, crop step: 8\n",
      "main.custom_modules.data_worker.data_worker ::     get_x_and_y_data() :: \n",
      "    Read detectors data shape: (119, 400)\n",
      "    Read defect data shape: (119, 400)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (149, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (149, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (152, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 8\n",
      "    The output df shape: (152, 432)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (149, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (149, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (152, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 8\n",
      "    The output df shape: (152, 432)\n",
      "main.custom_modules.data_worker.data_worker :: reshape_x_df_to_image_like_numpy() :: \n",
      "    The input df shape: (152, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 8\n",
      "    The output time array of crops shape: (954, 16, 16, 32)\n",
      "    The output amplitude array of crops shape: (954, 16, 16, 32)\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 44.4\n",
      "    The arr min before standardization: 0.0\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: 0.0\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 62.992\n",
      "    The arr min before standardization: -62.482\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: -0.9919037338074677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.(02-05)v_make_pred.ipynb ::             <module>() :: run: 2, crop step: 16\n",
      "main.custom_modules.data_worker.data_worker ::     get_x_and_y_data() :: \n",
      "    Read detectors data shape: (119, 400)\n",
      "    Read defect data shape: (119, 400)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (149, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (149, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (160, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 16\n",
      "    The output df shape: (160, 432)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_prediction() :: \n",
      "    The input df shape: (149, 430)\n",
      "    The crop size: 16\n",
      "    The output df shape: (149, 430)\n",
      "main.custom_modules.data_worker._dataframe_utils :: extend_df_for_crops_dividing() :: \n",
      "    The input df shape: (160, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 16\n",
      "    The output df shape: (160, 432)\n",
      "main.custom_modules.data_worker.data_worker :: reshape_x_df_to_image_like_numpy() :: \n",
      "    The input df shape: (160, 432)\n",
      "    The crop size: 16\n",
      "    The crop step: 16\n",
      "    The output time array of crops shape: (270, 16, 16, 32)\n",
      "    The output amplitude array of crops shape: (270, 16, 16, 32)\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 44.4\n",
      "    The arr min before standardization: 0.0\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: 0.0\n",
      "main.custom_modules.data_worker.data_worker ::     standardize_data() :: \n",
      "    The arr max before standardization: 62.992\n",
      "    The arr min before standardization: -62.482\n",
      "    The arr max after standardization: 1.0\n",
      "    The arr min after standardization: -0.9919037338074677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "for run in RUNS:\n",
    "    for crop_step in CROP_STEPS:\n",
    "        logger.debug(f'run: {run}, crop step: {crop_step}')\n",
    "        (orig_size_result_df, \n",
    "        extend_size_result_df,\n",
    "        orig_size_reference_df, \n",
    "        extend_size_reference_df) = make_pred_fast(load_model, PATH_TO_DATA[f'run_{run}'], XSHIFT, CROP_SIZE, crop_step)\n",
    "\n",
    "        #dw.draw_defects_map(orig_size_reference_df, title = f'REFERENCE run: {run}, crop step: {crop_step}')\n",
    "        #dw.draw_defects_map(orig_size_result_df, title = f'PREDICTION run: {run}, crop step: {crop_step}')\n",
    "\n",
    "        path_to_run = f'data/drawing_data/model_id=v{MODEL_VER}n{MODEL_NUM}/run_{run}/' \n",
    "        res_file_name = f'model_id=v{MODEL_VER}n{MODEL_NUM}_crop(size={CROP_SIZE},step={crop_step})_shift(x={XSHIFT},y=0).xlsx'\n",
    "        \n",
    "        if not os.path.exists(path_to_run):\n",
    "            os.makedirs(path_to_run)\n",
    "        \n",
    "        with pd.ExcelWriter(os.path.join(path_to_run, res_file_name)) as writer:  \n",
    "            orig_size_result_df.to_excel(writer, sheet_name='orig_size_result')\n",
    "            extend_size_result_df.to_excel(writer, sheet_name='extend_size_result')\n",
    "            \n",
    "            orig_size_reference_df.to_excel(writer, sheet_name='orig_size_reference')\n",
    "            extend_size_reference_df.to_excel(writer, sheet_name='extend_size_reference')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
