{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde58157-7750-45b9-a343-b46e3c74b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies import\n",
    "from common_dependencies import *\n",
    "logger = logging.getLogger('main.model_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a4710f-8299-4683-a397-97aa0948f406",
   "metadata": {},
   "source": [
    "# Загрузка модели для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473d54e-a577-4b17-b1dd-c299b813e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)\n",
    "np.random.seed(290)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94819c6e-fd4a-45bd-a50d-55ecde00bdba",
   "metadata": {},
   "source": [
    "## Поиск модели по идентификатору"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5aaa37-6b30-407b-8800-175394eb739f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_VER = 14\n",
    "MODEL_NUM = 2\n",
    "\n",
    "model_pathes = [path for path in pathlib.Path(f'networks/CNN/').rglob(f'*.keras') \n",
    "                     if re.search(rf'id=v0*{MODEL_VER}n0*{MODEL_NUM}',path.name)]\n",
    "if len(model_pathes) == 1:\n",
    "    PATH_TO_MODEL = model_pathes[0]\n",
    "else:\n",
    "    print(model_pathes)\n",
    "    raise ValueError('Few or none model have been found instead of one')\n",
    "\n",
    "print(f'{PATH_TO_MODEL=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a82eafb-72bd-48ee-8ecb-55b77e95c6ef",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b890b1-c36a-4a26-b725-695a5a2936d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(PATH_TO_MODEL)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=200,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb6505-7ee4-40f7-bcdd-e964450b1f93",
   "metadata": {},
   "source": [
    "# Загрузка данных для тестирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31fdb8-d087-4e91-95ff-19bb3a0f6cc4",
   "metadata": {},
   "source": [
    "## Параметры  выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d8c44-d63a-4f94-9f7a-2d45f2c2edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "XSHIFT = 200\n",
    "MAX_VAL = 1000\n",
    "CROP_SIZE = model.inputs[0].shape[1]\n",
    "dataset_desc =  {'test': (DatasetPartDescription(PATH_TO_DATA['run_1'],DataCrop(0,80,MAX_VAL,MAX_VAL),SlidingCrop(CROP_SIZE,1),XSHIFT),\n",
    "                          DatasetPartDescription(PATH_TO_DATA['run_2'],DataCrop(0,80,MAX_VAL,MAX_VAL),SlidingCrop(CROP_SIZE,1),XSHIFT)\n",
    "                            ,)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6f729d-cb43-439e-a18a-5742f727ddaa",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3b45a-e3f8-4b9f-a802-38c84500a171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = {'test':dict(zip(['x','y','bin'], [np.array(list(gen)) for gen in chain_dataset_gens(dataset_desc['test'])]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245db2e4-1590-4865-b1c6-b76448afd72c",
   "metadata": {},
   "source": [
    "## Размерности данных в обучающих выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c8886-1e5b-48e8-8d8f-5c3b2affd3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug('Dataset')\n",
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    logger.debug('|'*8+dataset_part_name+'|'*8)\n",
    "    for data_part_name, data_part in dataset_part.items():\n",
    "        logger.debug(f'{data_part_name}.shape: {data_part.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2dc8e-6ed4-44ad-a4c4-728763dd8532",
   "metadata": {},
   "source": [
    "## Какие части 2 файлов с данными относятся к конкретным выборкам (к тренировочной, тестовой, валидационной)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfe7e4-3327-445a-8c36-27b126d76ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#выборка данных\n",
    "# show parts took for learning\n",
    "all_rects = {'run_1': {'test':None,},  #\n",
    "             'run_2': {'test':None,}} #\n",
    "rects_colors = {'train':'red', 'val':'green', 'test':'yellow'}\n",
    "\n",
    "for run_name in all_rects.keys():\n",
    "    x_df, y_df = dw.get_x_and_y_data(*PATH_TO_DATA[run_name])\n",
    "    x_df = None\n",
    "    y_df = dw.roll_df(y_df, XSHIFT, 1)\n",
    "    for dataset_part_name in all_rects[run_name].keys():\n",
    "        # get all DatasetPartDescription for train, val or test\n",
    "        dataset_part_desc = dataset_desc[dataset_part_name]\n",
    "        # get all DatasetPartDescription for current run_name (run_1 or run_2)\n",
    "        dataset_part_desc = [dataset_part for dataset_part in dataset_part_desc if re.findall(r'run_\\d', dataset_part.data_path_tuple[0])[0] == run_name]\n",
    "        # put rects list to all_rects[run_name][dataset_part_name]\n",
    "        all_rects[run_name][dataset_part_name] = [Rectangle((dataset_part.file_data_crop.left, dataset_part.file_data_crop.top), \n",
    "                           dataset_part.file_data_crop.width, dataset_part.file_data_crop.height, \n",
    "                           facecolor=rects_colors[dataset_part_name], alpha=0.4, edgecolor='white')\n",
    "                                                  for dataset_part in dataset_part_desc]\n",
    "        \n",
    "    res_rects = list(itertools.chain(*[run_rects for run_rects_name, run_rects in all_rects[run_name].items()]))\n",
    "    if res_rects:\n",
    "        dw.draw_defects_map_with_rectangles_owerlap(y_df, res_rects, title = f'The parts took for learning from {run_name} (red - train, green - validate, yellow - test)')\n",
    "    else:\n",
    "        dw.draw_defects_map(y_df, title = f'The parts took for learning from {run_name} (red - train, green - validate, yellow - test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce56e1-494e-458d-9925-c39e4a45214a",
   "metadata": {},
   "source": [
    "# Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c0334-2ccc-4da9-a1df-f2b04bea8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(dataset['test']['x'], \n",
    "                     dataset['test']['bin'], \n",
    "                     batch_size=32, \n",
    "                     verbose=0, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b073e-05e6-4303-ae6c-68899d7dd962",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('|'*8,'test','|'*8)#,'\\n',train_res,'\\n')\n",
    "print(*[(key,value) for (key,value) in res.items()],sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4190e23-41c0-4c2d-ad2b-f24ae2a280e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset = {'test':dict(zip(['x','y'], [dw.get_batch_generator(part,5000) for part in chain_dataset_gens(dataset_desc['test'])] ))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15934777-b8c4-44dd-b5dd-7c58524c9b64",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''metric_dict_14 = {'train':None,'val':None,'test':None}\n",
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    print('|'*8+dataset_part_name+'|'*8)\n",
    "    metrics = [keras.metrics.AUC(name='PR_AUC', curve='PR'),\n",
    "               keras.metrics.AUC(name='ROC_AUC', curve='ROC'),\n",
    "               keras.metrics.BinaryCrossentropy(name='BinaryCrossentropy'),\n",
    "               keras.metrics.BinaryAccuracy(name='BinaryAccuracy'),\n",
    "               keras.metrics.MeanSquaredError(name='MeanSquaredError'),\n",
    "               keras.metrics.Precision(name='Precision'),\n",
    "               keras.metrics.Recall(name='Recall'),\n",
    "               keras.metrics.TruePositives(name='TruePositives'),\n",
    "               keras.metrics.FalsePositives(name='FalsePositives'),\n",
    "               keras.metrics.TrueNegatives(name='TrueNegatives'),\n",
    "               keras.metrics.FalseNegatives(name='FalseNegatives')]\n",
    "\n",
    "    for (x_buffer,  y_buffer) in zip(*dataset_part.values()):\n",
    "        x_buffer = np.pad(x_buffer, ((0,0),(1,1),(1,1),(0,0)), 'reflect')\n",
    "        #print(x_buffer.shape)\n",
    "        res = load_model.predict(x_buffer, verbose=0)\n",
    "        for metric in metrics:\n",
    "            metric.update_state(y_buffer, res)\n",
    "\n",
    "    metric_dict_14[dataset_part_name] = {metric.get_config()[\"name\"]:metric.result() for metric in metrics}\n",
    "    for metric in metrics:\n",
    "        #print(f'{metric.get_config()[\"name\"]}:{metric.result():.6f}')\n",
    "        metric.reset_state()''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbacc5e-2586-4708-924e-44172fce81ed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''CROP_SIZE = 16\n",
    "\n",
    "dataset_desc =  {'train': (DatasetPartDescription(PATH_TO_DATA['run_1'],DataCrop(0,0,MAX_VAL,MAX_VAL),SlidingCrop(CROP_SIZE,1),XSHIFT),),\n",
    "                 'val': (DatasetPartDescription(PATH_TO_DATA['run_2'],DataCrop(0,0,MAX_VAL,40),SlidingCrop(CROP_SIZE,1),XSHIFT),),\n",
    "                 'test': (DatasetPartDescription(PATH_TO_DATA['run_2'],DataCrop(0,40,MAX_VAL,MAX_VAL),SlidingCrop(CROP_SIZE,1),XSHIFT),)}\n",
    "\n",
    "dataset = {'train':dict(zip(['x','y'], [dw.get_batch_generator(part,5000) for part in chain_dataset_gens(dataset_desc['train'])] )),\n",
    "           'val':dict(zip(['x','y'], [dw.get_batch_generator(part,5000) for part in chain_dataset_gens(dataset_desc['val'])] )),\n",
    "           'test':dict(zip(['x','y'], [dw.get_batch_generator(part,5000) for part in chain_dataset_gens(dataset_desc['test'])] ))}''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721ffd3-b13b-4657-961e-a53a5a2de670",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''metric_dict_16 = {'train':None,'val':None,'test':None}\n",
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    print('|'*8+dataset_part_name+'|'*8)\n",
    "    metrics = [keras.metrics.AUC(name='PR_AUC', curve='PR'),\n",
    "               keras.metrics.AUC(name='ROC_AUC', curve='ROC'),\n",
    "               keras.metrics.BinaryCrossentropy(name='BinaryCrossentropy'),\n",
    "               keras.metrics.BinaryAccuracy(name='BinaryAccuracy'),\n",
    "               keras.metrics.MeanSquaredError(name='MeanSquaredError'),\n",
    "               keras.metrics.Precision(name='Precision'),\n",
    "               keras.metrics.Recall(name='Recall'),\n",
    "               keras.metrics.TruePositives(name='TruePositives'),\n",
    "               keras.metrics.FalsePositives(name='FalsePositives'),\n",
    "               keras.metrics.TrueNegatives(name='TrueNegatives'),\n",
    "               keras.metrics.FalseNegatives(name='FalseNegatives')]\n",
    "\n",
    "    for (x_buffer,  y_buffer) in zip(*dataset_part.values()):\n",
    "        #x_buffer = np.pad(x_buffer, ((0,0),(1,1),(1,1),(0,0)), 'reflect')\n",
    "        #print(x_buffer.shape)\n",
    "        res = load_model.predict(x_buffer, verbose=0)\n",
    "        for metric in metrics:\n",
    "            metric.update_state(y_buffer, res)\n",
    "\n",
    "    metric_dict_16[dataset_part_name] = {metric.get_config()[\"name\"]:metric.result() for metric in metrics}\n",
    "    for metric in metrics:\n",
    "        #print(f'{metric.get_config()[\"name\"]}:{metric.result():.6f}')\n",
    "        metric.reset_state()''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f511ba-a1f5-48c2-9900-8d2426fe76c0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''for (data_part1, data_part2) in zip(metric_dict_14.keys(), metric_dict_16.keys()):\n",
    "    print('|'*8+data_part1+'|'*8)\n",
    "    for ((metric_name1, metric_res1), (metric_name2, metric_res2)) in zip(metric_dict_14[data_part1].items(), metric_dict_16[data_part2].items()):\n",
    "        print('|'*8+metric_name1+'|'*8)\n",
    "        print(f'Вход 16 на 16: {metric_res2}')\n",
    "        print(f'Вход 14 на 14: {metric_res1}')\n",
    "        print(f'Метрика для 14 на 14 это {metric_res1/metric_res2*100:.2f}% от метрики 16 на 16')\n",
    "        print()''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5f690-484b-4f7a-9e04-c7f1b2fda79a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''# тест модели\n",
    "res_list = list()\n",
    "for crop_step in CROP_STEPS:\n",
    "    (test_x_time_gen, \n",
    "     test_x_amp_gen, \n",
    "     test_y_binary_gen,\n",
    "     test_y_depth_gen) = get_dataset_gen(PATH_TO_DATA[f'run_{run}'], XSHIFT, DataCrop(None,None,None,200), CROP_SIZE, 20)\n",
    "    \n",
    "    test_x_time = np.stack([crop for crop in test_x_time_gen])\n",
    "    test_x_amp = np.stack([crop for crop in test_x_amp_gen])\n",
    "    test_y_binary = np.array([binary for binary in test_y_binary_gen])\n",
    "    test_y_depth = np.array([depth for depth in test_y_depth_gen])\n",
    "    \n",
    "    res = load_model.evaluate([test_x_time, test_x_amp], test_y_binary, batch_size = 32, return_dict=True)\n",
    "    res_list.append({'res':res,'crop_size':CROP_SIZE,'crop_step':crop_step})''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209cfe0-5d54-4e6f-9aff-5e1fab49f21b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''for line in res_list:\n",
    "    print(f'crop_size: {line[\"crop_size\"]}')\n",
    "    print(f'crop_size: {line[\"crop_step\"]}')\n",
    "    print(line['res'])\n",
    "    print()''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
