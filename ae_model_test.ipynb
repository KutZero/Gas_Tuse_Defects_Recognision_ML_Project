{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde58157-7750-45b9-a343-b46e3c74b5b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dependencies import\n",
    "from common_dependencies import *\n",
    "from typing import NamedTuple\n",
    "#import model_versions as mv\n",
    "import logging\n",
    "logger = logging.getLogger(f'main.ae_model_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fe4a33-b6cc-4237-91f1-4e2995f4437b",
   "metadata": {},
   "source": [
    "# Загрузка модели для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecfcd4-dc70-4a02-bab1-9109c8e78913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# детерминация случайных величин, отвечающих за выбор первоначальных весов и биасов\n",
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)\n",
    "np.random.seed(290)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb4d759-e5ec-4d23-833b-e0b7f86c328c",
   "metadata": {},
   "source": [
    "## Поиск модели по идентификатору"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffbbfc-0d72-4c7e-9c84-b76d63d477fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# какую модель взять\n",
    "MODEL_VER = 1\n",
    "MODEL_NUM = 1\n",
    "\n",
    "model_pathes = [path for path in pathlib.Path(f'networks/AE/').rglob(f'*.keras') \n",
    "                     if re.search(rf'id=v0*{MODEL_VER}n0*{MODEL_NUM}',path.name)]\n",
    "\n",
    "if len(model_pathes) == 1:\n",
    "    PATH_TO_MODEL = model_pathes[0]\n",
    "else:\n",
    "    print(model_pathes)\n",
    "    raise ValueError('Few or none model have been found instead of one')\n",
    "\n",
    "\n",
    "PATH_TO_SAVE_IMAGES = pathlib.Path('data/generated_content/AE models results')/PATH_TO_MODEL.parent.stem/PATH_TO_MODEL.stem\n",
    "\n",
    "print(f'{PATH_TO_MODEL=}')\n",
    "print(f'{PATH_TO_SAVE_IMAGES=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54468c-ede8-4909-9759-6f494408d078",
   "metadata": {},
   "source": [
    "### Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e8555-950d-4d97-ba17-e1648e96e1d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "model = keras.models.load_model(PATH_TO_MODEL)\n",
    "ENCODED_SIZE = min([layer.output.shape[1] for layer in model.layers]) \n",
    "\n",
    "if not os.path.exists(PATH_TO_SAVE_IMAGES):\n",
    "    os.makedirs(PATH_TO_SAVE_IMAGES)\n",
    "\n",
    "print(model.summary())\n",
    "'''tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=200,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=False,\n",
    ")''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa3ad74-9029-4f6b-abe8-e7a4cc62f7d9",
   "metadata": {},
   "source": [
    "# Загрузка данных для тестирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd3a54-736f-41d3-857b-3549c744d780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T13:00:06.037757Z",
     "iopub.status.busy": "2024-06-09T13:00:06.037566Z",
     "iopub.status.idle": "2024-06-09T13:00:06.039428Z",
     "shell.execute_reply": "2024-06-09T13:00:06.039192Z",
     "shell.execute_reply.started": "2024-06-09T13:00:06.037747Z"
    }
   },
   "source": [
    "## Параметры  выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf461c0-86ef-4815-a965-1e766c1f33b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_VAL = 1000 # не трогать\n",
    "XSHIFT = 200 # не трогать\n",
    "dataset_desc = {'run_1': (DatasetPartDescription(PATH_TO_DATA['run_1'],DataCrop(0,0,MAX_VAL,MAX_VAL),SlidingCrop(1,1),XSHIFT),),\n",
    "                'run_2': (DatasetPartDescription(PATH_TO_DATA['run_2'],DataCrop(0,0,MAX_VAL,MAX_VAL),SlidingCrop(1,1),XSHIFT),)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab63790-5a53-43ad-b805-82a118c8e75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#входные и выходные данные\n",
    "# reading\n",
    "dataset = {'run_1':dict(zip(['x','y','bin'], [np.array(list(gen)) for gen in chain_dataset_gens(dataset_desc['run_1'])])),\n",
    "           'run_2':dict(zip(['x','y','bin'], [np.array(list(gen)) for gen in chain_dataset_gens(dataset_desc['run_2'])]))}\n",
    "\n",
    "# squueze datasets\n",
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    for data_part_name, data_part in dataset_part.items():\n",
    "        if data_part_name == 'x':\n",
    "            dataset[dataset_part_name][data_part_name] = data_part.reshape(-1,64)\n",
    "        if data_part_name == 'y':\n",
    "            dataset[dataset_part_name][data_part_name] = data_part.reshape(-1)\n",
    "        if data_part_name == 'bin':\n",
    "            dataset[dataset_part_name][data_part_name] = data_part.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ed827-4a8b-4f7a-8253-4a7978426b1d",
   "metadata": {},
   "source": [
    "## Размерности данных в обучающих выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0235e3-c2fc-4d74-9e7b-37f8ae439477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying\n",
    "logger.debug('\\nDataset')\n",
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    logger.debug('|'*8+dataset_part_name+'|'*8)\n",
    "    for data_part_name, data_part in dataset_part.items():\n",
    "        logger.debug(f'{data_part_name}.shape: {data_part.shape}, max={np.max(data_part)}, min={np.min(data_part)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b0239-ad6b-481d-b32a-38efced713f8",
   "metadata": {},
   "source": [
    "# Анализ качетсва кодирования и декодирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168b37f-7d0d-423c-9eae-58c113db2fa0",
   "metadata": {},
   "source": [
    "## Кодирование и декодирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25eac6f-75f9-499d-b043-ce83f51fd217",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    dataset[dataset_part_name]['autoencode_result'] = model.predict(dataset_part['x'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9de2d-26e9-4d04-9d3c-234c4b944ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    print(dataset_part_name)\n",
    "    for part_name, part in dataset_part.items():\n",
    "        print(part_name,part.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb06b8-d540-41df-b5e1-486e7b4a437f",
   "metadata": {},
   "source": [
    "## Вывести примеры кодирования и декодирования графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e55bad-8710-4afb-9525-f27c21304905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example of autoencode nondef graphs\n",
    "\n",
    "FONT_SIZE = 20\n",
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    path_to_save = f'{PATH_TO_SAVE_IMAGES}/{dataset_part_name}'\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "    \n",
    "    for i in range(10):\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_figwidth(12)\n",
    "        fig.set_figheight(8)\n",
    "\n",
    "        time = dataset_part['x'][dataset_part['bin']!=0][i,1:32]\n",
    "        amp = dataset_part['x'][dataset_part['bin']!=0][i,33:]\n",
    "        \n",
    "        pred_time = dataset_part['autoencode_result'][dataset_part['bin']!=0][i,1:32]\n",
    "        pred_amp = dataset_part['autoencode_result'][dataset_part['bin']!=0][i,33:]\n",
    "        \n",
    "        ax.plot(time, amp, c='blue', linestyle='--', label='Исходные данные')\n",
    "        ax.plot(pred_time, pred_amp, c='red', label='Декодированные данные')\n",
    "        \n",
    "        ax.set_title(f'Результат декодирования для замера датчика в области дефекта',fontsize=FONT_SIZE)\n",
    "        ax.legend(fontsize = FONT_SIZE)\n",
    "        ax.set_xlabel('Время',fontsize=FONT_SIZE)\n",
    "        ax.set_ylabel('Амплитуда',fontsize=FONT_SIZE)\n",
    "        ax.tick_params(axis='both', labelsize = FONT_SIZE)\n",
    "        ax.grid(True)\n",
    "        #plt.show()\n",
    "        plt.savefig(f'{path_to_save}/defect_{i}.jpg', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    for i in range(10):\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_figwidth(12)\n",
    "        fig.set_figheight(8)\n",
    "\n",
    "        time = dataset_part['x'][dataset_part['bin']==0][i,1:32]\n",
    "        amp = dataset_part['x'][dataset_part['bin']==0][i,33:]\n",
    "        \n",
    "        pred_time = dataset_part['autoencode_result'][dataset_part['bin']==0][i,1:32]\n",
    "        pred_amp = dataset_part['autoencode_result'][dataset_part['bin']==0][i,33:]\n",
    "    \n",
    "        ax.plot(time, amp, c='blue', linestyle='--', label='Исходные данные')\n",
    "        ax.plot(pred_time, pred_amp, c='red', label='Декодированные данные')\n",
    "        \n",
    "        ax.set_title(f'Результат декодирования для замера датчика в области без дефектов',fontsize=FONT_SIZE)\n",
    "        #ax.legend(fontsize = FONT_SIZE)\n",
    "        ax.set_xlabel('Время',fontsize=FONT_SIZE)\n",
    "        ax.set_ylabel('Амплитуда',fontsize=FONT_SIZE)\n",
    "        ax.tick_params(axis='both', labelsize = FONT_SIZE)\n",
    "        ax.grid(True)\n",
    "        #plt.show()\n",
    "        plt.savefig(f'{path_to_save}/nondefect_{i}.jpg', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58b272-1a7c-43c7-a3e7-d592f6315dbb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# The loss function is just an example, the reduction is the important one\n",
    "#model.compile(optimizer=keras.optimizers.Adam(0.01), \n",
    "#              loss=keras.losses.MeanSquaredError(reduction=tf.compat.v1.losses.Reduction.NONE) ) # keep your original optimizer\n",
    "\n",
    "\n",
    "#pred_y = model.predict(dataset['run_1']['x'], verbose=0)\n",
    "#loss = keras.losses.MeanSquaredError(reduction='sum')(dataset['run_1']['x'], pred_y) # sum_over_batch_size\n",
    "#print(loss)\n",
    "# And then you'll get each loss for each instance within a batch\n",
    "#for dataset_part_name, dataset_part in dataset.items():\n",
    "#    res = model.evaluate(dataset_part['x'], dataset_part['y'], batch_size=128)\n",
    "#    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8ca65-e8f4-4113-83b1-4706a44e9039",
   "metadata": {},
   "source": [
    "## Посчитать функцию ошибки для каждого наблюдения в выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e48fa-4e42-486a-9b69-506aab781da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    dataset[dataset_part_name]['all_losses'] = np.array([float(keras.losses.MeanSquaredError(reduction='sum')(true_res, pred_res)) for \n",
    "                                                true_res, pred_res in \n",
    "                                                         zip(dataset[dataset_part_name]['x'], model.predict(dataset[dataset_part_name]['x'], verbose=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66baa24b-33be-4f51-a230-f5d258f6a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['run_1']['all_losses'].shape)\n",
    "print(dataset['run_2']['all_losses'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb1e9d-2cee-443b-8188-11341edca2bd",
   "metadata": {},
   "source": [
    "## Вывести распределение размеров функции ошибки для наблюдений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9fd89-2547-4dcb-9489-728c8bf4ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_SIZE=15\n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "fig.suptitle(f'Гистограммы распределения величины функции ошибки (Mean squared error) к разным частям выборки', fontsize=FONT_SIZE)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "#axes[0].set_title('Для всех наблюдений в выборке',fontsize = FONT_SIZE)\n",
    "axes[0].set_title('Для наблюдений, относящихся к местам дефектов',fontsize = FONT_SIZE)\n",
    "axes[1].set_title('Для наблюдений, не относящихся к местам дефектов',fontsize = FONT_SIZE)\n",
    "\n",
    "for ((dataset_part_name, dataset_part),clr) in zip(dataset.items(),['red', 'blue']):\n",
    "    #axes[0].hist(dataset_part['all_losses'], label=f'файл: {dataset_part_name}', color=clr, alpha=0.5)\n",
    "    axes[0].hist(dataset_part['all_losses'][dataset_part['bin']!=0], label=f'файл: {dataset_part_name}', color=clr, alpha=0.5)\n",
    "    axes[1].hist(dataset_part['all_losses'][dataset_part['bin']==0], label=f'файл: {dataset_part_name}', color=clr, alpha=0.5)\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Значение mean squared error',fontsize = FONT_SIZE)\n",
    "    ax.set_ylabel('Количество наблюдений',fontsize = FONT_SIZE)\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='both', which='both', labelsize = FONT_SIZE)\n",
    "    ax.margins(0.05)\n",
    "    ax.legend(fontsize = FONT_SIZE)\n",
    "    \n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.15, hspace=0.1)\n",
    "plt.savefig(f'{PATH_TO_SAVE_IMAGES}/losses_encode_to_{ENCODED_SIZE}.jpg', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a6639-21a4-471f-87cb-dfb54503b8d8",
   "metadata": {},
   "source": [
    "# Анализ результатов кодирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff672eb-76db-44ef-83af-01d87687ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предполагая, что у вас есть обученная модель ae\n",
    "#enc_model = keras.Model(inputs=ae.input, outputs=ae.get_layer('enc_output').output)  # Получение модели для вывода слоя enc_output\n",
    "enc_model = keras.Model(inputs=model.input, outputs=min([layer.output for layer in model.layers], key=lambda x: x.shape[1]))\n",
    "\n",
    "for dataset_part_name, dataset_part in dataset.items():\n",
    "    dataset[dataset_part_name]['encode_result'] = enc_model.predict(dataset[dataset_part_name]['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801eaaeb-b250-45f2-ae8c-1611846a2474",
   "metadata": {},
   "source": [
    "## Можно запустить для моделей со слоем кодирования равным 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae9d4d-d5d3-47f4-8f02-2f070c149f1a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "FONT_SIZE = 20\n",
    "name = f\"\"\"Отображения признаков из 64-x мерного пространства на двух мерное\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "fig.suptitle(name, fontsize=FONT_SIZE)\n",
    "fig.set_figwidth(22)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "for (i, (dataset_part_name, dataset_part)) in zip(range(len(dataset)), dataset.items()):\n",
    "    axes[i].set_title(f'Результат для {dataset_part_name}', fontsize=FONT_SIZE)\n",
    "    axes[i].scatter(dataset_part['encode_result'][dataset_part['bin']==0,0], \n",
    "                    dataset_part['encode_result'][dataset_part['bin']==0,1], c='blue', s=3, label='non defect')\n",
    "    \n",
    "    axes[i].scatter(dataset_part['encode_result'][dataset_part['bin']!=0,0], \n",
    "                    dataset_part['encode_result'][dataset_part['bin']!=0,1], c='red', s=3, label='defect')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('X',fontsize = FONT_SIZE)\n",
    "    ax.set_ylabel('Y',fontsize = FONT_SIZE)\n",
    "    ax.grid(True)\n",
    "    ax.tick_params(axis='both', which='both', labelsize = FONT_SIZE)\n",
    "    ax.margins(0.05)\n",
    "    ax.legend(fontsize = FONT_SIZE)\n",
    "\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.15, hspace=0.2)\n",
    "\n",
    "plt.savefig(f'{PATH_TO_SAVE_IMAGES}/encoded_to_{ENCODED_SIZE}_distribution.jpg', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55869f9-c265-4814-a43e-f1e97cbbf4b4",
   "metadata": {},
   "source": [
    "### Если на распределении видны скопления точек - можноо руками тут выделиль эти точки срезами по осям x и y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab2040-deb7-4531-9a54-5212a02bd06b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''df_1 = pd.DataFrame(data=dataset['run_1']['encode_result'],columns=['x','y'])\n",
    "df_2 = pd.DataFrame(data=dataset['run_2']['encode_result'],columns=['x','y'])\n",
    "\n",
    "def label_class(row):\n",
    "    if row['y'] < 0.2:\n",
    "        return 0\n",
    "    if row['x'] < 0.2:\n",
    "        return 1\n",
    "    elif row['x'] >= 0.2 and row['x'] < 0.6:\n",
    "        return 2\n",
    "    else :\n",
    "        return 3\n",
    "        \n",
    "df_1['class'] = df_1.apply(label_class, axis=1)\n",
    "df_2['class'] = df_2.apply(label_class, axis=1)\n",
    "\n",
    "display(df_1)\n",
    "display(df_2)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d36f13-0905-40b5-bed7-97728d32d24f",
   "metadata": {},
   "source": [
    "### Если выделил точки - тут можно отобразить их положение в файлах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe351f-721f-4ad6-8eaa-ff80c617d812",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''for class_i in range(4):\n",
    "    df = df_1[df_1['class']==class_i]\n",
    "    \n",
    "    class_vals = df.index.to_list()\n",
    "    \n",
    "    x_df, y_df = dataset.get_x_and_y_data_dfs(dw.DataPart(path=PATH_TO_DATA['run_1']))\n",
    "\n",
    "    xshift = 200\n",
    "    crop_size = 1\n",
    "    crop_step = 1\n",
    "    \n",
    "    x_df = dw.roll_df(x_df, xshift, 1)\n",
    "    y_df = dw.roll_df(y_df, xshift, 1)\n",
    "\n",
    "    it = 0\n",
    "    \n",
    "    for i in range(0, y_df.shape[0] - crop_size + 1, crop_step):  \n",
    "        for j in range(0, y_df.shape[1] - crop_size + 1, crop_step): \n",
    "            if it in class_vals:\n",
    "                y_df.iloc[i:i+crop_size, j:j+crop_size] = 1\n",
    "            else:\n",
    "                y_df.iloc[i:i+crop_size, j:j+crop_size] = 0\n",
    "            it+=1\n",
    "            \n",
    "    dw.draw_defects_map(y_df, \n",
    "        title = f'Точки run_1 относящиеся к классу {class_i} ({len(class_vals)} точек)',\n",
    "        path_to_save = f'run_1_encoded_to_2_class={class_i}_dot_quantity={len(class_vals)}.jpg')\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9aea8c-7bb3-44e2-8aaf-35a876462ab5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''for class_i in range(4):\n",
    "    df = df_2[df_2['class']==class_i]\n",
    "    \n",
    "    class_vals = df.index.to_list()\n",
    "    \n",
    "    x_df, y_df = dataset.get_x_and_y_data_dfs(dw.DataPart(path=PATH_TO_DATA['run_1']))\n",
    "\n",
    "    xshift = 200\n",
    "    crop_size = 1\n",
    "    crop_step = 1\n",
    "    \n",
    "    x_df = dw.roll_df(x_df, xshift, 1)\n",
    "    y_df = dw.roll_df(y_df, xshift, 1)\n",
    "\n",
    "    it = 0\n",
    "    \n",
    "    for i in range(0, y_df.shape[0] - crop_size + 1, crop_step):  \n",
    "        for j in range(0, y_df.shape[1] - crop_size + 1, crop_step): \n",
    "            if it in class_vals:\n",
    "                y_df.iloc[i:i+crop_size, j:j+crop_size] = 1\n",
    "            else:\n",
    "                y_df.iloc[i:i+crop_size, j:j+crop_size] = 0\n",
    "            it+=1\n",
    "            \n",
    "    dw.draw_defects_map(y_df, \n",
    "        title = f'Точки run_2 относящиеся к классу {class_i} ({len(class_vals)} точек)',\n",
    "        path_to_save = f'run_2_encoded_to_2_class={class_i}_dot_quantity={len(class_vals)}.jpg')\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae21e8f-c715-4a92-b1e4-5f12734db9cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''df_1 = pd.DataFrame(data=dataset['run_1']['encode_result'],columns=['x','y'])\n",
    "df_2 = pd.DataFrame(data=dataset['run_2']['encode_result'],columns=['x','y'])\n",
    "\n",
    "df_1['down'] = df_1['y'].map(lambda y: 1 if y < 0.2 else 0)\n",
    "df_2['down'] = df_2['y'].map(lambda y: 1 if y < 0.2 else 0)\n",
    "\n",
    "print(f'run_1 up: {df_1[df_1[\"down\"]==0].shape[0]}')\n",
    "print(f'run_1 down: {df_1[df_1[\"down\"]==1].shape[0]}')\n",
    "print(f'run_2 up: {df_2[df_2[\"down\"]==0].shape[0]}')\n",
    "print(f'run_2 down: {df_2[df_2[\"down\"]==1].shape[0]}')\n",
    "#display(df_1)\n",
    "#display(df_2)\n",
    "\n",
    "x_df, y_df = dataset.get_x_and_y_data_dfs(dw.DataPart(path=PATH_TO_DATA['run_1']))\n",
    "\n",
    "xshift = 200\n",
    "crop_size = 1\n",
    "crop_step = 1\n",
    "\n",
    "x_df = dw.roll_df(x_df, xshift, 1)\n",
    "y_df = dw.roll_df(y_df, xshift, 1)\n",
    "\n",
    "down = iter(df_1['down'].values)\n",
    "\n",
    "for i in range(0, y_df.shape[0] - crop_size + 1, crop_step):  \n",
    "        for j in range(0, y_df.shape[1] - crop_size + 1, crop_step):  \n",
    "            y_df.iloc[i:i+crop_size, j:j+crop_size] = next(down)\n",
    "\n",
    "dw.draw_defects_map(y_df, \n",
    "                    title = f'Точки run_1 относящиеся к нижнему скоплению - яркие ({df_1[df_1[\"down\"]==1].shape[0]} точек), к верхнему - темные ({df_1[df_1[\"down\"]==0].shape[0]} точек)')\n",
    "\n",
    "\n",
    "x_df, y_df = dataset.get_x_and_y_data_dfs(dw.DataPart(path=PATH_TO_DATA['run_1']))\n",
    "x_df = dw.roll_df(x_df, xshift, 1)\n",
    "y_df = dw.roll_df(y_df, xshift, 1)\n",
    "\n",
    "down = iter(df_2['down'].values)\n",
    "\n",
    "for i in range(0, y_df.shape[0] - crop_size + 1, crop_step):  \n",
    "        for j in range(0, y_df.shape[1] - crop_size + 1, crop_step):  \n",
    "            y_df.iloc[i:i+crop_size, j:j+crop_size] = next(down)\n",
    "\n",
    "dw.draw_defects_map(y_df, title = f'Точки run_2 относящиеся к нижнему скоплению - яркие ({df_2[df_2[\"down\"]==1].shape[0]} точек), к верхнему - темные ({df_2[df_2[\"down\"]==0].shape[0]} точек)')''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096ab12-ea8d-4e6f-8bb3-a5cfb48cce43",
   "metadata": {},
   "source": [
    "## Можно запустить для моделей со слоем кодирования более 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b8022-f498-4fbc-ad64-17fb4ae178ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(data=dataset['run_1']['encode_result'])\n",
    "#display(df_1)\n",
    "df_1.columns = [f\"{col} параметр\" for col in df_1.columns.to_list()]\n",
    "axarr = df_1.hist(figsize=(20,20), bins=ENCODED_SIZE)\n",
    "\n",
    "for ax_row in axarr:\n",
    "    for ax in ax_row:\n",
    "        ax.set_xlabel(\"Значение\")\n",
    "        ax.set_ylabel(\"Кол-во наблюдений\")\n",
    "\n",
    "axarr[0][0].axvline(1.5, c='r', linewidth=2)\n",
    "axarr[1][1].axvline(1.5, c='r', linewidth=2)\n",
    "axarr[2][3].axvline(2, c='r', linewidth=2)\n",
    "axarr[3][0].axvline(2.5, c='r', linewidth=2)\n",
    "axarr[3][2].axvline(1, c='r', linewidth=2)\n",
    "axarr[3][3].axvline(1, c='r', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c418dfb-028b-46d5-a5b1-acfdc31e27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(data=dataset['run_2']['encode_result'])\n",
    "#display(df_1)\n",
    "df_2.columns = [f\"{col} параметр\" for col in df_2.columns.to_list()]\n",
    "axarr = df_2.hist(figsize=(20,20), bins=ENCODED_SIZE)\n",
    "\n",
    "for ax_row in axarr:\n",
    "    for ax in ax_row:\n",
    "        ax.set_xlabel(\"Значение\")\n",
    "        ax.set_ylabel(\"Кол-во наблюдений\")\n",
    "\n",
    "axarr[0][0].axvline(1.5, c='r', linewidth=2)\n",
    "axarr[1][1].axvline(1.5, c='r', linewidth=2)\n",
    "axarr[2][3].axvline(2, c='r', linewidth=2)\n",
    "axarr[3][0].axvline(2.5, c='r', linewidth=2)\n",
    "axarr[3][2].axvline(1, c='r', linewidth=2)\n",
    "axarr[3][3].axvline(1, c='r', linewidth=2)\n",
    "\n",
    "# 0 1.5\n",
    "# 5 1.5\n",
    "# 11 2\n",
    "# 12 2.5\n",
    "# 14 1\n",
    "# 15 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fdc121-978f-4b9e-8751-2e9b19a81109",
   "metadata": {},
   "source": [
    "#### Если есть распределения в форме параболы - можно по ним разделить точки на N классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a697025-100b-4147-834e-1c887cc6cd37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(data=dataset['run_1']['encode_result'])\n",
    "#display(df_1)\n",
    "df_1.hist(figsize=(20,20), bins=20)\n",
    "# 0 1.5\n",
    "# 5 1.5\n",
    "# 11 2\n",
    "# 12 2.5\n",
    "# 14 1\n",
    "# 15 1\n",
    "df_1['0_div'] = df_1[0].map(lambda x: 1 if x > 1.5 else 0)\n",
    "df_1['5_div'] = df_1[5].map(lambda x: 1 if x > 1.5 else 0)\n",
    "df_1['11_div'] = df_1[11].map(lambda x: 1 if x > 2 else 0)\n",
    "df_1['12_div'] = df_1[12].map(lambda x: 1 if x > 2.5 else 0)\n",
    "df_1['14_div'] = df_1[14].map(lambda x: 1 if x > 1 else 0)\n",
    "df_1['15_div'] = df_1[15].map(lambda x: 1 if x > 1 else 0)\n",
    "\n",
    "display(df_1)\n",
    "df_1_unique_rows = df_1[['0_div','5_div','11_div','12_div','14_div','15_div']].drop_duplicates(ignore_index=True)\n",
    "display(df_1_unique_rows)\n",
    "\n",
    "new_column = []\n",
    "for i in range(df_1.shape[0]):\n",
    "    row = df_1.iloc[i]\n",
    "    for j in range(df_1_unique_rows.shape[0]):\n",
    "        class_row = df_1_unique_rows.iloc[j]\n",
    "        if  (row['0_div'] == class_row['0_div'] and\n",
    "            row['5_div'] == class_row['5_div'] and\n",
    "            row['11_div'] == class_row['11_div'] and\n",
    "            row['12_div'] == class_row['12_div'] and\n",
    "            row['14_div'] == class_row['14_div'] and\n",
    "            row['15_div'] == class_row['15_div']):\n",
    "            new_column.append(j)\n",
    "            \n",
    "#print(new_column)\n",
    "df_1['class'] = new_column\n",
    "df_1['class'].hist(figsize=(10,10), bins=64)\n",
    "\n",
    "\n",
    "\n",
    "'''for class_i in range(64):\n",
    "    x_df, y_df = dataset.get_x_and_y_data_dfs(dw.DataPart(path=PATH_TO_DATA['run_1']))\n",
    "\n",
    "    xshift = 200\n",
    "    crop_size = 1\n",
    "    crop_step = 1\n",
    "    \n",
    "    x_df = dw.roll_df(x_df, xshift, 1)\n",
    "    y_df = dw.roll_df(y_df, xshift, 1)\n",
    "\n",
    "    it = 0\n",
    "    items_iter = df_1[df_1['class']==class_i].index.to_list()\n",
    "    \n",
    "    for i in range(0, y_df.shape[0] - crop_size + 1, crop_step):  \n",
    "            for j in range(0, y_df.shape[1] - crop_size + 1, crop_step):\n",
    "                if it in items_iter:\n",
    "                    y_df.iloc[i:i+crop_size, j:j+crop_size] = 1\n",
    "                else:\n",
    "                    y_df.iloc[i:i+crop_size, j:j+crop_size] = 0\n",
    "                it+=1\n",
    "                \n",
    "    path_to_save = f'{PATH_TO_SAVE_IMAGES}/run_1/classes'\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "        \n",
    "    dw.draw_defects_map(y_df, title = f'Точки относящиеся к классу {class_i} ({len(items_iter)} точек)',\n",
    "                        path_to_save = f'{path_to_save}/class={class_i}_dot_quantity={len(items_iter)}.jpg')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69b61f-4584-4ceb-9448-93a85283815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_chosen_classes(path_to_data, file_num, new_title, path_to_save, choosen_df, xshift, crop_size, crop_step):\n",
    "    x_df, y_df = dataset.get_x_and_y_data_dfs(dw.DataPart(path=path_to_data))\n",
    "\n",
    "    y_df = dw.roll_df(y_df, xshift, 1)\n",
    "    y_df = dw.match_df_for_crops_dividing(y_df, crop_size, crop_step)\n",
    "\n",
    "    new_y_df = y_df.copy()\n",
    "    new_y_df.iloc[:,:] = 0\n",
    "    \n",
    "    it = iter(sorted(choosen_df.index.to_list()))\n",
    "    def_ind = next(it)\n",
    "    cur_ind = 0\n",
    "    all_defects = 0\n",
    "    current_defects = 0\n",
    "    for i in range(0, y_df.shape[0] - crop_size + 1, crop_step):  \n",
    "        for j in range(0, y_df.shape[1] - crop_size + 1, crop_step):\n",
    "            value = np.max(y_df.iloc[i:i+crop_size, j:j+crop_size].to_numpy())\n",
    "            if value > 0:\n",
    "                all_defects += 1\n",
    "    \n",
    "    for i in range(0, new_y_df.shape[0] - crop_size + 1, crop_step):  \n",
    "        for j in range(0, new_y_df.shape[1] - crop_size + 1, crop_step): \n",
    "            if cur_ind == def_ind:\n",
    "                #print(def_ind)\n",
    "                if np.max(y_df.iloc[i:i+crop_size, j:j+crop_size].to_numpy()) > 0:\n",
    "                    current_defects += 1\n",
    "                new_y_df.iloc[i:i+crop_size, j:j+crop_size] += 1\n",
    "                try:\n",
    "                    def_ind = next(it)\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "            cur_ind += 1\n",
    "    \n",
    "    title = f'Развернутая карта дефектов' # для файла {file_num}\n",
    "    dw.draw_defects_map(y_df, title=title, path_to_save=f'{path_to_save}/{title} для файла {file_num}.jpeg')#, pcolormesh_cmap='Greys') #черно белое/\n",
    "    #title = f'Развернутая карта предсказания зон дефектов с помощью t-SNE' # для файла {file_num}\n",
    "    dw.draw_defects_map(new_y_df, \n",
    "                        title=f'{new_title}\\n({current_defects} дефектов из {all_defects})', \n",
    "                        path_to_save=f'{path_to_save}/{new_title.split('\\n')[0]}{new_title.split('\\n')[2]} для файла {file_num}.jpeg')#, pcolormesh_cmap='Greys')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efec8e4-9517-4245-a496-fc68352c8b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def defect(path_to_data, xshift=200, crop_size=1,crop_step=1):\n",
    "    x_df, y_df = dataset.get_x_and_y_data_dfs(dw.DataPart(path=path_to_data))\n",
    "\n",
    "    y_df = dw.roll_df(y_df, xshift, 1)\n",
    "    y_df = dw.match_df_for_crops_dividing(y_df, crop_size, crop_step)\n",
    "    \n",
    "    defects = []\n",
    "    for i in range(0, y_df.shape[0] - crop_size + 1, crop_step):  \n",
    "        for j in range(0, y_df.shape[1] - crop_size + 1, crop_step):\n",
    "            defects.append(np.max(y_df.iloc[i:i+crop_size, j:j+crop_size].to_numpy()))  \n",
    "    return defects\n",
    "\n",
    "df_1['defect'] = defect(PATH_TO_DATA['run_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d859f09-1d9b-4aaf-a3fc-3f37f2b15d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_1.shape)\n",
    "def_df = df_1.query(\"defect > 0\")\n",
    "print(def_df.shape)\n",
    "print(sorted(def_df['class'].unique()))\n",
    "\n",
    "often_df = df_1[df_1['class'].isin(def_df['class'].unique())]\n",
    "\n",
    "draw_chosen_classes(PATH_TO_DATA['run_1'], 1,\n",
    "    f'Развернутая карта для классов\\n {sorted(def_df['class'].unique())} \\n (все классы в которые попало хоть 1 наблюдение для дефектной зоны) \\n({often_df.shape[0]} точек из {df_1.shape[0]})',\n",
    "    f'{PATH_TO_SAVE_IMAGES}/run_1/few_classes', often_df, 200, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566cd650-f9b8-49f6-87fa-188975fbdd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''axarr = df_1[df_1['defect']==0]['class'].hist(figsize=(5,5), bins=64)\n",
    "\n",
    "axarr.set_title('Гистограмма кол-ва наблюдений, \\nне относящихся к зонам дефектов для каждого класса')\n",
    "axarr.set_xlabel(\"Номер класса\")\n",
    "axarr.set_ylabel(\"Кол-во наблюдений\")'''\n",
    "\n",
    "nd,bd,pd = plt.hist(df_1[df_1['defect']>0]['class'].to_list(), bins=64)\n",
    "n,b,p = plt.hist(df_1[df_1['defect']==0]['class'].to_list(), bins=64)\n",
    "\n",
    "FONT_SIZE = 15\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5)\n",
    "\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='both', which='both', labelsize = FONT_SIZE)\n",
    "ax.margins(0.05)\n",
    "ax.legend(fontsize = FONT_SIZE)\n",
    "\n",
    "ax.hist(weights=n/max(n), bins=64, label=f'Дефект', color='r', alpha=0.5)\n",
    "\n",
    "#ax.hist(df_1[df_1['defect']>0]['class'], density=True, bins=64, label=f'Дефект', color='r', alpha=0.5)\n",
    "#ax.hist(df_1[df_1['defect']==0]['class'], density=True, bins=64, label=f'Не дефект', color='b', alpha=0.5)\n",
    "\n",
    "ax.set_title('Гистограмма соотношения кол-во наблюдений относящегося и нет к зонам дефектов')\n",
    "ax.set_xlabel(\"Номер класса\")\n",
    "ax.set_ylabel(\"Кол-во наблюдений\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf69db6-983e-4011-ae1c-506624ab96d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n,b,p = plt.hist(df_1['class'].to_list(), bins=64)\n",
    "val = 2500\n",
    "options = [i for i, item in enumerate(n) if item <= val] \n",
    " \n",
    "often_df = df_1[df_1['class'].isin(options)]\n",
    "#draw_chosen_classes(path_to_data, file_num, new_title, path_to_save, choosen_df, xshift, crop_size, crop_step):\n",
    "draw_chosen_classes(PATH_TO_DATA['run_1'], 1,\n",
    "                    f'Развернутая карта для классов\\n {options} \\n (в каждом меньше или равно {val} элементов) \\n({often_df.shape[0]} точек из {df_1.shape[0]})',\n",
    "                    f'{PATH_TO_SAVE_IMAGES}/run_1/few_classes', often_df, 200, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfa364-5798-4018-8d01-f601091fb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{[1,2,3,4,5]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b106e44-d13e-43c0-80d4-088b443c836b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''df_2 = pd.DataFrame(data=dataset['run_2']['encode_result'])\n",
    "#display(df_1)\n",
    "df_2.hist(figsize=(20,20), bins=20)\n",
    "# 0 1.5\n",
    "# 5 1.5\n",
    "# 11 2\n",
    "# 12 2.5\n",
    "# 14 1\n",
    "# 15 1\n",
    "df_2['0_div'] = df_2[0].map(lambda x: 1 if x > 1.5 else 0)\n",
    "df_2['5_div'] = df_2[5].map(lambda x: 1 if x > 1.5 else 0)\n",
    "df_2['11_div'] = df_2[11].map(lambda x: 1 if x > 2 else 0)\n",
    "df_2['12_div'] = df_2[12].map(lambda x: 1 if x > 2.5 else 0)\n",
    "df_2['14_div'] = df_2[14].map(lambda x: 1 if x > 1 else 0)\n",
    "df_2['15_div'] = df_2[15].map(lambda x: 1 if x > 1 else 0)\n",
    "\n",
    "display(df_2)\n",
    "df_2_unique_rows = df_2[['0_div','5_div','11_div','12_div','14_div','15_div']].drop_duplicates(ignore_index=True)\n",
    "display(df_2_unique_rows)\n",
    "\n",
    "new_column = []\n",
    "for i in range(df_2.shape[0]):\n",
    "    row = df_2.iloc[i]\n",
    "    for j in range(df_2_unique_rows.shape[0]):\n",
    "        class_row = df_2_unique_rows.iloc[j]\n",
    "        if  (row['0_div'] == class_row['0_div'] and\n",
    "            row['5_div'] == class_row['5_div'] and\n",
    "            row['11_div'] == class_row['11_div'] and\n",
    "            row['12_div'] == class_row['12_div'] and\n",
    "            row['14_div'] == class_row['14_div'] and\n",
    "            row['15_div'] == class_row['15_div']):\n",
    "            new_column.append(j)\n",
    "            \n",
    "print(len(new_column))\n",
    "df_2['class'] = new_column\n",
    "\n",
    "df_2['class'].hist(figsize=(10,10), bins=64)\n",
    "\n",
    "for class_i in range(64):\n",
    "    x_df, y_df = dataset.get_x_and_y_data_dfs(dw.DataPart(path=PATH_TO_DATA['run_2']))\n",
    "\n",
    "    xshift = 200\n",
    "    crop_size = 1\n",
    "    crop_step = 1\n",
    "    \n",
    "    x_df = dw.roll_df(x_df, xshift, 1)\n",
    "    y_df = dw.roll_df(y_df, xshift, 1)\n",
    "\n",
    "    it = 0\n",
    "    items_iter = df_2[df_2['class']==class_i].index.to_list()\n",
    "    \n",
    "    for i in range(0, y_df.shape[0] - crop_size + 1, crop_step):  \n",
    "            for j in range(0, y_df.shape[1] - crop_size + 1, crop_step):\n",
    "                if it in items_iter:\n",
    "                    y_df.iloc[i:i+crop_size, j:j+crop_size] = 1\n",
    "                else:\n",
    "                    y_df.iloc[i:i+crop_size, j:j+crop_size] = 0\n",
    "                it+=1\n",
    "    \n",
    "    dw.draw_defects_map(y_df, title = f'Точки run_2 относящиеся к классу {class_i} ({len(items_iter)} точек)',\n",
    "                        path_to_save = f'run_2_encoded_to_16_class={class_i}_dot_quantity={len(items_iter)}.jpg')''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
