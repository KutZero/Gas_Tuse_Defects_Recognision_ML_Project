{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e9457-0887-469b-830b-6f7396be6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies import\n",
    "from common_dependencies import *\n",
    "from itertools import chain\n",
    "import logging\n",
    "logger = logging.getLogger('main.make_pred.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34591ee-be65-42f8-8e4b-a8d2f49cee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for files with original data\n",
    "PATH_TO_DATA = {\n",
    "    'run_1': \n",
    "        ('data/original_data/run_1/run1_WM32_data.csv',\n",
    "        'data/original_data/run_1/run1_WM32_defects.csv',\n",
    "        'data/original_data/run_1/run1_WM32_pipe.csv'),\n",
    "    'run_2':\n",
    "        ('data/original_data/run_2/run2_WM32_data.csv',\n",
    "        'data/original_data/run_2/run2_WM32_defects.csv',\n",
    "        'data/original_data/run_2/run2_WM32_pipe.csv')\n",
    "}\n",
    "\n",
    "\n",
    "PATH_TO_MODEL = 'networks/CNN'\n",
    "RUNS = [2, 1]\n",
    "MODEL_VER = '14'\n",
    "MODEL_NUM = '01'\n",
    "XSHIFT = 200\n",
    "\n",
    "for name in os.listdir(PATH_TO_MODEL):\n",
    "    res = re.match(F'(id=v{MODEL_VER}n{MODEL_NUM}).*', name)\n",
    "    if not res is None:\n",
    "        PATH_TO_MODEL += '/' + res[0]\n",
    "        break\n",
    "\n",
    "# детерминация случайных величин, отвечающих за выбор первоначальных весов и биасов\n",
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3135c-1cb6-4061-b326-664c758c1944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "load_model = keras.models.load_model(PATH_TO_MODEL)\n",
    "CROP_SIZE = load_model.inputs[0].shape[1]\n",
    "CROP_STEPS = [1] #[CROP_SIZE, CROP_SIZE//2, CROP_SIZE//4, CROP_SIZE//8]\n",
    "print(load_model.summary())\n",
    "print(f'{CROP_SIZE=}')\n",
    "print(f'{CROP_STEPS=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ebd918-e535-4bd3-90d2-4e06660bc392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    load_model,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=200,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194db4d-2777-4eff-80b9-cd61937abe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_fast(model, \n",
    "                   path_to_data_tuple: tuple(),\n",
    "                   x_shift: int,\n",
    "                   crop_size: int, \n",
    "                   crop_step: int):\n",
    "\n",
    "    x_df, y_df = dw.get_x_and_y_data(*path_to_data_tuple)\n",
    "\n",
    "    x_df = dw.roll_df(x_df, x_shift, 1)\n",
    "    y_df = dw.roll_df(y_df, x_shift, 1)\n",
    "\n",
    "    or_rows = x_df.shape[0]\n",
    "    or_cols = x_df.shape[1]\n",
    "    ex_x_df = dw.extend_df_for_prediction(x_df, crop_size)\n",
    "    ex_x_df = dw.extend_df_for_crops_dividing(ex_x_df, crop_size, crop_step)\n",
    "    ex_y_df = dw.extend_df_for_prediction(y_df, crop_size)\n",
    "    ex_y_df = dw.extend_df_for_crops_dividing(ex_y_df, crop_size, crop_step)\n",
    "    ex_rows = ex_x_df.shape[0]\n",
    "    ex_cols = ex_x_df.shape[1]\n",
    "    \n",
    "    x_arr = dw.df_to_numpy(ex_x_df)\n",
    "    y_arr = ex_y_df.to_numpy()\n",
    "    \n",
    "    #x_arr_time = dw.standardize_data(x_arr[:,:,:32])\n",
    "    #x_arr_amp = dw.standardize_data(x_arr[:,:,32:])\n",
    "\n",
    "    # normalize_data\n",
    "    # standardize_datav\n",
    "    \n",
    "    x_arr = np.concatenate([dw.normalize_data(x_arr[:,:,:32]), dw.normalize_data(x_arr[:,:,32:])],axis=2)\n",
    "    #y_arr = dw.standardize_data(y_arr)\n",
    "    \n",
    "    #x_arr_time_crops_gen = dw.get_crop_generator(x_arr_time, crop_size, crop_step)\n",
    "    #x_arr_amp_crops_gen = dw.get_crop_generator(x_arr_amp, crop_size, crop_step)\n",
    "    \n",
    "    x_crops_gen = dw.get_batch_generator(dw.get_crop_generator(x_arr, crop_size, crop_step), 15000)\n",
    "    #x_time_crops_gen = dw.get_batch_generator(dw.get_crop_generator(x_arr[:,:,:32], crop_size, crop_step), 15000)\n",
    "    #x_amp_crops_gen = dw.get_batch_generator(dw.get_crop_generator(x_arr[:,:,32:], crop_size, crop_step), 15000)\n",
    "    #y_binary_gen = (1 if np.sum(crop > 0) else 0 for crop in dw.get_crop_generator(y_arr, crop_size, crop_step))\n",
    "    #y_data_depth_gen = (np.max(crop) for crop in dw.get_crop_generator(y_arr, crop_size, crop_step))\n",
    "\n",
    "    \n",
    "    \n",
    "    #x_time = np.stack([crop for crop in x_arr_time_crops_gen])\n",
    "    #x_amp = np.stack([crop for crop in x_arr_amp_crops_gen])\n",
    "    #x_data = dw.get_batch_generator(x_crops_gen, 15000) #np.array(list(x_crops_gen))\n",
    "    #y_binary = np.array(list(y_binary_gen))\n",
    "    #y_depth = np.array([depth for depth in y_data_depth_gen])\n",
    "\n",
    "    # 1 output\n",
    "    res = list()\n",
    "    for x in x_crops_gen:\n",
    "        #x = np.pad(x, ((0,0),(1,1),(1,1),(0,0)), 'reflect')\n",
    "        res.append(model.predict(x)[:,0])\n",
    "        #print(model.predict(x)[:,0].shape)\n",
    "    res = np.concatenate(res)\n",
    "    #print(res.shape)\n",
    "    res_it = iter(res)\n",
    "\n",
    "    # 2 outputs\n",
    "    '''res = np.array(model.predict([x_data_time, x_data_amp]))\n",
    "    res = np.squeeze(res, axis=2)\n",
    "    bool_res = res[0,:]\n",
    "    depth_res = res[1,:] \n",
    "    bool_res_it = iter(bool_res) \n",
    "    depth_res_it = iter(depth_res) \n",
    "    res_it = bool_res_it'''\n",
    "    \n",
    "    def fill_by_arrays(df_cell_value):\n",
    "        return list()\n",
    "    def add_number_to_arrays(df_cell_value, number):\n",
    "        df_cell_value.append(number)\n",
    "        return df_cell_value\n",
    "    extend_size_result_df = pd.DataFrame(data=0.0, \n",
    "                             columns=ex_x_df.columns, \n",
    "                             index=ex_x_df.index)\n",
    "    \n",
    "    #extend_size_result_df = extend_size_result_df.map(fill_by_arrays)\n",
    "\n",
    "    for i in range(0, ex_rows - crop_size + 1, crop_step):\n",
    "        for j in range(0,  ex_cols - crop_size + 1, crop_step):\n",
    "            temp_add = next(res_it)\n",
    "            #print(temp_add)\n",
    "            #extend_size_result_df.iloc[i:i+crop_size, j:j+crop_size] = \\\n",
    "            #    extend_size_result_df.iloc[i:i+crop_size, j:j+crop_size].map(lambda x: add_number_to_arrays(x, temp_add))\n",
    "            if temp_add >= 0.5:\n",
    "                extend_size_result_df.iloc[i:i+crop_size, j:j+crop_size] = \\\n",
    "                    extend_size_result_df.iloc[i:i+crop_size, j:j+crop_size].map(lambda x: x+1)\n",
    "            else:\n",
    "                extend_size_result_df.iloc[i:i+crop_size, j:j+crop_size] = \\\n",
    "                    extend_size_result_df.iloc[i:i+crop_size, j:j+crop_size].map(lambda x: x-1)\n",
    "                \n",
    "    orig_size_result_df = extend_size_result_df.iloc[crop_size-1:, crop_size-1:].iloc[:or_rows, :or_cols]\n",
    "    \n",
    "    return orig_size_result_df, extend_size_result_df, y_df, ex_y_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9103895-3237-45e4-b8ea-ef51c63e5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_quartile(df_cell):\n",
    "    q1 = [item for item in df_cell if item < 0.25]\n",
    "    q2 = [item for item in df_cell if item >= 0.25 and item < 0.5]\n",
    "    q3 = [item for item in df_cell if item >= 0.5 and item < 0.75]\n",
    "    q4 = [item for item in df_cell if item >= 0.75]\n",
    "    qrt = [len(q1), len(q2), len(q3), len(q4)]\n",
    "    ind = qrt.index(max(qrt))\n",
    "    if ind == 0:\n",
    "        return np.mean(q1)\n",
    "    elif ind == 1:\n",
    "        return np.mean(q2)\n",
    "    elif ind == 2:\n",
    "        return np.mean(q3)\n",
    "    else:\n",
    "        return np.mean(q4)\n",
    "\n",
    "def calc_half(df_cell):\n",
    "    h1 = [item for item in df_cell if item < 0.5]\n",
    "    h2 = [item for item in df_cell if item >= 0.5]\n",
    "    qrt = [len(h1), len(h2)]\n",
    "    ind = qrt.index(max(qrt))\n",
    "    \n",
    "    if ind == 0:\n",
    "        return np.mean(h1)\n",
    "    else:\n",
    "        return np.mean(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc6ea9-3f1e-44a6-8a24-7d05b95722ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in RUNS:\n",
    "    for crop_step in CROP_STEPS:\n",
    "        logger.debug(f'run: {run}, crop step: {crop_step}')\n",
    "        (orig_size_result_df, \n",
    "        extend_size_result_df,\n",
    "        orig_size_reference_df, \n",
    "        extend_size_reference_df) = make_pred_fast(load_model, PATH_TO_DATA[f'run_{run}'], XSHIFT, CROP_SIZE, crop_step)\n",
    "\n",
    "        path_to_file = f'images/models predicts/model_id=v{MODEL_VER}n{MODEL_NUM}_old_math_reduce/run_{run}'\n",
    "\n",
    "        \n",
    "        reduce_funcs = [max, min, np.mean, calc_half, calc_quartile]\n",
    "        \n",
    "        if not os.path.exists(path_to_file):\n",
    "            os.makedirs(path_to_file)\n",
    "\n",
    "        dw.draw_defects_map(orig_size_reference_df, \n",
    "                            title = f'REFERENCE run = {run}',\n",
    "                            path_to_save = f'{path_to_file}/REFERENCE run = {run}.jpg')\n",
    "        \n",
    "        dw.draw_defects_map(orig_size_result_df, \n",
    "                            title = f'PREDICTION run: {run}, crop step = {crop_step}, crop size = {CROP_SIZE}',\n",
    "                            path_to_save = f'{path_to_file}/PREDICTION run = {run}, crop step = {crop_step}, crop size = {CROP_SIZE}.jpg')\n",
    "            \n",
    "        dw.draw_defects_map_with_reference_owerlap(orig_size_result_df, orig_size_reference_df, \n",
    "                            title = f'OWERLAPPED PREDICTION run: {run}, crop step = {crop_step}, crop size = {CROP_SIZE}',\n",
    "                            path_to_save = f'{path_to_file}/OWERLAPPED PREDICTION run = {run}, crop step = {crop_step}, crop size = {CROP_SIZE}.jpg')\n",
    "\n",
    "        \"\"\"for func in reduce_funcs:\n",
    "            func_path_to_file = f'{path_to_file}/{func.__name__}'\n",
    "            \n",
    "            if not os.path.exists(func_path_to_file):\n",
    "                os.makedirs(func_path_to_file)\n",
    "\n",
    "            or_temp = orig_size_result_df.map(lambda x: func(x))\n",
    "            \n",
    "            dw.draw_defects_map(or_temp, \n",
    "                            title = f'PREDICTION {func.__name__} run: {run}, crop step = {crop_step}, crop size = {CROP_SIZE}',\n",
    "                            path_to_save = f'{func_path_to_file}/PREDICTION {func.__name__} run = {run}, crop step = {crop_step}, crop size = {CROP_SIZE}.jpg')\n",
    "            \n",
    "            dw.draw_defects_map_with_reference_owerlap(or_temp, orig_size_reference_df, \n",
    "                            title = f'OWERLAPPED PREDICTION {func.__name__} run: {run}, crop step = {crop_step}, crop size = {CROP_SIZE}',\n",
    "                            path_to_save = f'{func_path_to_file}/OWERLAPPED PREDICTION {func.__name__} run = {run}, crop step = {crop_step}, crop size = {CROP_SIZE}.jpg')\n",
    "\n",
    "            \n",
    "            binary = np.arange(0.05,1,0.05)\"\"\"\n",
    "\n",
    "            for bina in binary:\n",
    "                bin_func_path_to_file = path_to_file #f'{func_path_to_file}/raw' #f'{func_path_to_file}/binary_{bina}'\n",
    "            \n",
    "                if not os.path.exists(bin_func_path_to_file):\n",
    "                    os.makedirs(bin_func_path_to_file)\n",
    "\n",
    "                temp = or_temp.map(lambda x: 1 if x >= bina else 0)\n",
    "                \n",
    "                dw.draw_defects_map(temp, \n",
    "                        title = f'PREDICTION {func.__name__} binary_{bina:.02f} run = {run}, crop step = {crop_step}, crop size = {CROP_SIZE}',\n",
    "                        path_to_save = f'{bin_func_path_to_file}/PREDICTION {func.__name__} binary_{bina:.02f} run = {run}, crop step = {crop_step}, crop size = {CROP_SIZE}.jpg')\n",
    "\n",
    "                bin_func_path_to_file = f'{func_path_to_file}/owerlapped' #f'{func_path_to_file}/binary_{bina}'\n",
    "            \n",
    "                if not os.path.exists(bin_func_path_to_file):\n",
    "                    os.makedirs(bin_func_path_to_file)\n",
    "                \n",
    "                dw.draw_defects_map_with_reference_owerlap(temp, orig_size_reference_df, \n",
    "                                title = f'OWERLAPPED PREDICTION {func.__name__} binary_{bina:.02f} run = {run}, crop step = {crop_step}, crop size = {CROP_SIZE}',\n",
    "                                path_to_save = f'{bin_func_path_to_file}/OWERLAPPED PREDICTION {func.__name__} binary_{bina:.02f} run = {run}, crop step = {crop_step}, crop size = {CROP_SIZE}.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3f32d-e150-4179-a310-4a181b8b2cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
