{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e9457-0887-469b-830b-6f7396be6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies import\n",
    "from common_dependencies import *\n",
    "from itertools import chain\n",
    "import logging\n",
    "logger = logging.getLogger('main.make_pred.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34591ee-be65-42f8-8e4b-a8d2f49cee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for files with original data\n",
    "PATH_TO_DATA = {\n",
    "    'run_1': \n",
    "        ('data/original_data/run_1/run1_WM32_data.csv',\n",
    "        'data/original_data/run_1/run1_WM32_defects.csv',\n",
    "        'data/original_data/run_1/run1_WM32_pipe.csv'),\n",
    "    'run_2':\n",
    "        ('data/original_data/run_2/run2_WM32_data.csv',\n",
    "        'data/original_data/run_2/run2_WM32_defects.csv',\n",
    "        'data/original_data/run_2/run2_WM32_pipe.csv')\n",
    "}\n",
    "\n",
    "\n",
    "PATH_TO_MODEL = 'networks/CNN'\n",
    "RUNS = [2, 1]\n",
    "MODEL_VER = '14'\n",
    "MODEL_NUM = '01'\n",
    "XSHIFT = 200\n",
    "\n",
    "for name in os.listdir(PATH_TO_MODEL):\n",
    "    res = re.match(F'(id=v{MODEL_VER}n{MODEL_NUM}).*', name)\n",
    "    if not res is None:\n",
    "        PATH_TO_MODEL += '/' + res[0]\n",
    "        break\n",
    "\n",
    "# детерминация случайных величин, отвечающих за выбор первоначальных весов и биасов\n",
    "tf.compat.v1.set_random_seed(290)\n",
    "tf.random.set_seed(290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3135c-1cb6-4061-b326-664c758c1944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "load_model = keras.models.load_model(PATH_TO_MODEL)\n",
    "CROP_SIZE = load_model.inputs[0].shape[1]\n",
    "CROP_STEPS = [CROP_SIZE, CROP_SIZE//2, CROP_SIZE//4, CROP_SIZE//8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194db4d-2777-4eff-80b9-cd61937abe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_fast(model, \n",
    "                   path_to_data_tuple: tuple(),\n",
    "                   x_shift: int,\n",
    "                   crop_size: int, \n",
    "                   crop_step: int):\n",
    "\n",
    "    x_df, y_df = dw.get_x_and_y_data(*path_to_data_tuple)\n",
    "\n",
    "    x_df = dw.roll_df(x_df, x_shift, 1)\n",
    "    y_df = dw.roll_df(y_df, x_shift, 1)\n",
    "\n",
    "    or_rows = x_df.shape[0]\n",
    "    or_cols = x_df.shape[1]\n",
    "    ex_x_df = dw.extend_df_for_prediction(x_df, crop_size)\n",
    "    ex_x_df = dw.extend_df_for_crops_dividing(ex_x_df, crop_size, crop_step)\n",
    "    ex_y_df = dw.extend_df_for_prediction(y_df, crop_size)\n",
    "    ex_y_df = dw.extend_df_for_crops_dividing(ex_y_df, crop_size, crop_step)\n",
    "    ex_rows = ex_x_df.shape[0]\n",
    "    ex_cols = ex_x_df.shape[1]\n",
    "    \n",
    "    x_arr = dw.df_to_numpy(ex_x_df)\n",
    "    y_arr = ex_y_df.to_numpy()\n",
    "    \n",
    "    #x_arr_time = dw.standardize_data(x_arr[:,:,:32])\n",
    "    #x_arr_amp = dw.standardize_data(x_arr[:,:,32:])\n",
    "\n",
    "    x_arr = np.concatenate([dw.normalize_data(x_arr[:,:,:32]), dw.normalize_data(x_arr[:,:,32:])],axis=2)\n",
    "    y_arr = dw.normalize_data(y_arr)\n",
    "    \n",
    "    #x_arr_time_crops_gen = dw.get_crop_generator(x_arr_time, crop_size, crop_step)\n",
    "    #x_arr_amp_crops_gen = dw.get_crop_generator(x_arr_amp, crop_size, crop_step)\n",
    "    \n",
    "    x_crops_gen = dw.get_crop_generator(x_arr, crop_size, crop_step)\n",
    "    y_binary_gen = (1 if np.sum(crop > 0) else 0 for crop in dw.get_crop_generator(y_arr, crop_size, crop_step))\n",
    "    #y_data_depth_gen = (np.max(crop) for crop in dw.get_crop_generator(y_arr, crop_size, crop_step))\n",
    "\n",
    "    \n",
    "    \n",
    "    #x_time = np.stack([crop for crop in x_arr_time_crops_gen])\n",
    "    #x_amp = np.stack([crop for crop in x_arr_amp_crops_gen])\n",
    "    x_data = np.array(list(x_crops_gen))\n",
    "    y_binary = np.array(list(y_binary_gen))\n",
    "    #y_depth = np.array([depth for depth in y_data_depth_gen])\n",
    "\n",
    "    # 1 output\n",
    "    res = model.predict(x_data)[:,0]\n",
    "    res_it = iter(res)\n",
    "\n",
    "    # 2 outputs\n",
    "    '''res = np.array(model.predict([x_data_time, x_data_amp]))\n",
    "    res = np.squeeze(res, axis=2)\n",
    "    bool_res = res[0,:]\n",
    "    depth_res = res[1,:] \n",
    "    bool_res_it = iter(bool_res) \n",
    "    depth_res_it = iter(depth_res) \n",
    "    res_it = bool_res_it'''\n",
    "    \n",
    "    def fill_by_arrays(df_cell_value):\n",
    "        return list()\n",
    "    def add_number_to_arrays(df_cell_value, number):\n",
    "        df_cell_value.append(number)\n",
    "        return df_cell_value\n",
    "    extend_size_result_df = pd.DataFrame(data=0, \n",
    "                             columns=ex_x_df.columns, \n",
    "                             index=ex_x_df.index)\n",
    "    extend_size_result_df = extend_size_result_df.map(fill_by_arrays)\n",
    "\n",
    "    for i in range(0, ex_rows - crop_size + 1, crop_step):\n",
    "        for j in range(0,  ex_cols - crop_size + 1, crop_step):\n",
    "            temp_add = next(res_it)\n",
    "            extend_size_result_df.iloc[i:i+crop_size, j:j+crop_size] = \\\n",
    "                extend_size_result_df.iloc[i:i+crop_size, j:j+crop_size].map(lambda x: add_number_to_arrays(x, temp_add))\n",
    "\n",
    "    orig_size_result_df = extend_size_result_df.iloc[crop_size-1:, crop_size-1:].iloc[:or_rows, :or_cols]\n",
    "    \n",
    "    return orig_size_result_df, extend_size_result_df, y_df, ex_y_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc6ea9-3f1e-44a6-8a24-7d05b95722ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in RUNS:\n",
    "    for crop_step in CROP_STEPS:\n",
    "        logger.debug(f'run: {run}, crop step: {crop_step}')\n",
    "        (orig_size_result_df, \n",
    "        extend_size_result_df,\n",
    "        orig_size_reference_df, \n",
    "        extend_size_reference_df) = make_pred_fast(load_model, PATH_TO_DATA[f'run_{run}'], XSHIFT, CROP_SIZE, crop_step)\n",
    "\n",
    "        def calc_quartile(df_cell):\n",
    "            q1 = [item for item in df_cell if item < 0.25]\n",
    "            q2 = [item for item in df_cell if item >= 0.25 and item < 0.5]\n",
    "            q3 = [item for item in df_cell if item >= 0.5 and item < 0.75]\n",
    "            q4 = [item for item in df_cell if item >= 0.75]\n",
    "            qrt = [len(q1), len(q2), len(q3), len(q4)]\n",
    "            ind = qrt.index(max(qrt))\n",
    "            if ind == 0:\n",
    "                return np.mean(q1)\n",
    "            elif ind == 1:\n",
    "                return np.mean(q2)\n",
    "            elif ind == 2:\n",
    "                return np.mean(q3)\n",
    "            else:\n",
    "                return np.mean(q4)\n",
    "\n",
    "        def calc_half(df_cell):\n",
    "            h1 = [item for item in df_cell if item < 0.5]\n",
    "            h2 = [item for item in df_cell if item >= 0.5]\n",
    "            qrt = [len(h1), len(h2)]\n",
    "            ind = qrt.index(max(qrt))\n",
    "            \n",
    "            if ind == 0:\n",
    "                return np.mean(h1)\n",
    "            else:\n",
    "                return np.mean(h2)\n",
    "        \n",
    "        dw.draw_defects_map(orig_size_reference_df, title = f'REFERENCE run: {run}, crop step: {crop_step}, crop size: {CROP_SIZE}')\n",
    "        dw.draw_defects_map(orig_size_result_df.map(calc_quartile), title = f'PREDICTION QUART run: {run}, crop step: {crop_step}, crop size: {CROP_SIZE}')\n",
    "        dw.draw_defects_map(orig_size_result_df.map(calc_half), title = f'PREDICTION HALF run: {run}, crop step: {crop_step}, crop size: {CROP_SIZE}')\n",
    "        dw.draw_defects_map(orig_size_result_df.map(lambda x: np.max(x)), title = f'PREDICTION MAX run: {run}, crop step: {crop_step}, crop size: {CROP_SIZE}')\n",
    "        dw.draw_defects_map(orig_size_result_df.map(lambda x: np.min(x)), title = f'PREDICTION MIN run: {run}, crop step: {crop_step}, crop size: {CROP_SIZE}')\n",
    "\n",
    "                \n",
    "        #display(orig_size_result_df)\n",
    "        '''path_to_run = f'data/drawing_data/model_id=v{MODEL_VER}n{MODEL_NUM}/run_{run}/' \n",
    "        res_file_name = f'model_id=v{MODEL_VER}n{MODEL_NUM}_crop(size={CROP_SIZE},step={crop_step})_shift(x={XSHIFT},y=0).xlsx'\n",
    "        \n",
    "        if not os.path.exists(path_to_run):\n",
    "            os.makedirs(path_to_run)\n",
    "        \n",
    "        with pd.ExcelWriter(os.path.join(path_to_run, res_file_name)) as writer:  \n",
    "            orig_size_result_df.to_excel(writer, sheet_name='orig_size_result')\n",
    "            extend_size_result_df.to_excel(writer, sheet_name='extend_size_result')\n",
    "            \n",
    "            orig_size_reference_df.to_excel(writer, sheet_name='orig_size_reference')\n",
    "            extend_size_reference_df.to_excel(writer, sheet_name='extend_size_reference')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3f32d-e150-4179-a310-4a181b8b2cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
